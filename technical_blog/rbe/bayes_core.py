"""Core Bayesian inference functions - updates, sequential processing, and posterior predictive"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/rbe/01_bayes_core.ipynb.

# %% auto 0
__all__ = ['update', 'sequential', 'predictive', 'bayes_factor', 'interpret_bf', 'beta_binomial_update', 'normal_normal_update']

# %% ../../nbs/rbe/01_bayes_core.ipynb 3
import numpy as np
from typing import Optional, Union, List, Callable
from fastcore.test import test_eq, test_close
from fastcore.all import *
from .probability import normalize, sample

# %% ../../nbs/rbe/01_bayes_core.ipynb 6
def update(prior, # Prior probabilities
           likelihood, # Likelihood of evidence given hypothesis
           evidence=None # Optional evidence, defaults to sum(prior * likelihood)
           ):
    """Update prior beliefs with likelihood using Bayes' theorem."""
    prior = np.asarray(prior, dtype=np.float64)
    likelihood = np.asarray(likelihood, dtype=np.float64)
    
    # Validate inputs
    if prior.shape != likelihood.shape: raise ValueError(f"Prior and likelihood shapes don't match: {prior.shape} vs {likelihood.shape}")
    if np.any(prior < 0) or np.any(likelihood < 0): raise ValueError("Prior and likelihood must be non-negative")
    # Normalize prior if needed (common in practice)
    if not np.isclose(np.sum(prior), 1.0): prior = normalize(prior)
    # Compute evidence if not provided
    if evidence is None: evidence = np.sum(prior * likelihood)
    # Check for impossible observation
    if evidence == 0: raise ValueError("Impossible observation: zero evidence")
    # Numerical stability check
    if evidence < 1e-15:
        import warnings
        warnings.warn("Very small evidence value - numerical instability possible")
    
    return (prior * likelihood) / evidence


# %% ../../nbs/rbe/01_bayes_core.ipynb 12
def sequential(priors,  # prior probabilities of hypotheses 
               likelihoods, # likelihoods of observations given hypotheses
               evidences=None # evidence for each observation
               ):
    """Sequential Bayesian updates with multiple observations."""
    priors = np.asarray(priors, dtype=np.float64)
    likelihoods = np.asarray(likelihoods, dtype=np.float64)
    
    # Validate inputs
    if len(likelihoods) == 0:
        return np.array([priors])
    
    if likelihoods.ndim != 2:
        raise ValueError("Likelihoods must be 2D array (n_observations, n_hypotheses)")
    
    if likelihoods.shape[1] != len(priors):
        raise ValueError(f"Likelihood shape {likelihoods.shape} incompatible with prior length {len(priors)}")
    
    if evidences is None:
        evidences = [None] * len(likelihoods)
    elif len(evidences) != len(likelihoods):
        raise ValueError("Number of evidences must match number of likelihoods")
    
    # Perform sequential updates
    posterior = priors.copy()
    posteriors = [posterior.copy()]
    
    for likelihood, evidence in zip(likelihoods, evidences):
        posterior = update(posterior, likelihood, evidence)
        posteriors.append(posterior.copy())
    
    return np.array(posteriors)


# %% ../../nbs/rbe/01_bayes_core.ipynb 29
def predictive(posterior, likelihood_fn, n_samples=1000, rng=None):
    """Vectorized posterior predictive sampling."""
    if rng is None: rng = np.random.default_rng()
    
    posterior = normalize(posterior)
    param_samples = sample(posterior, n_samples, rng)
    
    # Group samples by parameter for efficient batch processing
    unique_params, counts = np.unique(param_samples, return_counts=True)
    
    predictions = []
    for param_idx, count in zip(unique_params, counts):
        obs_dist = normalize(likelihood_fn(param_idx))
        obs_samples = sample(obs_dist, count, rng)
        predictions.extend(obs_samples)
    
    # Shuffle to remove parameter ordering bias
    rng.shuffle(predictions)
    return np.array(predictions, dtype=int)


# %% ../../nbs/rbe/01_bayes_core.ipynb 36
def bayes_factor(likelihood1, likelihood2, data):
    "Calculate Bayes factor for hypothesis 1 vs 2 given `data`"
    # For single observation
    if np.isscalar(data):
        return likelihood1[data] / likelihood2[data]
    
    # For multiple observations (assuming independence)
    bf = 1.0
    for obs in data:
        bf *= likelihood1[obs] / likelihood2[obs]
    return bf

def interpret_bf(bf):
    "Interpret Bayes factor strength"
    if bf < 1/100:
        return "Decisive evidence against H1"
    elif bf < 1/10:
        return "Strong evidence against H1"
    elif bf < 1/3:
        return "Moderate evidence against H1"
    elif bf < 1:
        return "Weak evidence against H1"
    elif bf < 3:
        return "Weak evidence for H1"
    elif bf < 10:
        return "Moderate evidence for H1"
    elif bf < 100:
        return "Strong evidence for H1"
    else:
        return "Decisive evidence for H1"

# %% ../../nbs/rbe/01_bayes_core.ipynb 39
def beta_binomial_update(alpha, beta, successes, failures):
    "Update Beta prior with binomial data"
    return alpha + successes, beta + failures

def normal_normal_update(prior_mean, prior_var, data_mean, data_var, n_obs):
    "Update Normal prior with Normal likelihood"
    # Precision weighting
    prior_prec = 1 / prior_var
    data_prec = n_obs / data_var
    
    post_prec = prior_prec + data_prec
    post_mean = (prior_prec * prior_mean + data_prec * data_mean) / post_prec
    post_var = 1 / post_prec
    
    return post_mean, post_var

# %% ../../nbs/rbe/01_bayes_core.ipynb 42
__all__ = [
    # Core updates
    'update', 'sequential',
    
    # Posterior predictive
    'predictive',
    
    # Model comparison
    'bayes_factor', 'interpret_bf',
    
    # Conjugate priors
    'beta_binomial_update', 'normal_normal_update'
]
