"""Core Bayesian inference functions - updates, sequential processing, and posterior predictive"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/rbe/01_bayes_core.ipynb.

# %% auto 0
__all__ = ['update', 'sequential', 'predictive', 'bayes_factor', 'interpret_bf', 'beta_binomial_update', 'normal_normal_update']

# %% ../../nbs/rbe/01_bayes_core.ipynb 3
import numpy as np
from typing import Optional, Union, List, Callable
from fastcore.test import test_eq, test_close
from fastcore.all import *
from .probability import normalize, sample

# %% ../../nbs/rbe/01_bayes_core.ipynb 6
def update(prior, # Prior probabilities
           likelihood, # Likelihood of evidence given hypothesis
           evidence=None # Optional evidence, defaults to sum(prior * likelihood)
           ):
    """Update prior beliefs with likelihood using Bayes' theorem."""
    prior = np.asarray(prior, dtype=np.float64)
    likelihood = np.asarray(likelihood, dtype=np.float64)
    
    # Validate inputs
    if prior.shape != likelihood.shape: raise ValueError(f"Prior and likelihood shapes don't match: {prior.shape} vs {likelihood.shape}")
    if np.any(prior < 0) or np.any(likelihood < 0): raise ValueError("Prior and likelihood must be non-negative")
    # Normalize prior if needed (common in practice)
    if not np.isclose(np.sum(prior), 1.0): prior = normalize(prior)
    # Compute evidence if not provided
    if evidence is None: evidence = np.sum(prior * likelihood)
    # Check for impossible observation
    if evidence == 0: raise ValueError("Impossible observation: zero evidence")
    # Numerical stability check
    if evidence < 1e-15:
        import warnings
        warnings.warn("Very small evidence value - numerical instability possible")
    
    return (prior * likelihood) / evidence


# %% ../../nbs/rbe/01_bayes_core.ipynb 12
def sequential(priors,  # prior probabilities of hypotheses 
               likelihoods, # likelihoods of observations given hypotheses
               evidences=None # evidence for each observation
               ):
    """Sequential Bayesian updates with multiple observations."""
    priors = np.asarray(priors, dtype=np.float64)
    likelihoods = np.asarray(likelihoods, dtype=np.float64)
    
    # Validate inputs
    if len(likelihoods) == 0:
        return np.array([priors])
    
    if likelihoods.ndim != 2:
        raise ValueError("Likelihoods must be 2D array (n_observations, n_hypotheses)")
    
    if likelihoods.shape[1] != len(priors):
        raise ValueError(f"Likelihood shape {likelihoods.shape} incompatible with prior length {len(priors)}")
    
    if evidences is None:
        evidences = [None] * len(likelihoods)
    elif len(evidences) != len(likelihoods):
        raise ValueError("Number of evidences must match number of likelihoods")
    
    # Perform sequential updates
    posterior = priors.copy()
    posteriors = [posterior.copy()]
    
    for likelihood, evidence in zip(likelihoods, evidences):
        posterior = update(posterior, likelihood, evidence)
        posteriors.append(posterior.copy())
    
    return np.array(posteriors)


# %% ../../nbs/rbe/01_bayes_core.ipynb 29
def predictive(posterior, likelihood_fn, n_samples=1000, rng=None):
    """Vectorized posterior predictive sampling."""
    if rng is None: rng = np.random.default_rng()
    
    posterior = normalize(posterior)
    param_samples = sample(posterior, n_samples, rng)
    
    # Group samples by parameter for efficient batch processing
    unique_params, counts = np.unique(param_samples, return_counts=True)
    
    predictions = []
    for param_idx, count in zip(unique_params, counts):
        obs_dist = normalize(likelihood_fn(param_idx))
        obs_samples = sample(obs_dist, count, rng)
        predictions.extend(obs_samples)
    
    # Shuffle to remove parameter ordering bias
    rng.shuffle(predictions)
    return np.array(predictions, dtype=int)


# %% ../../nbs/rbe/01_bayes_core.ipynb 37
def bayes_factor(likelihood1, # likelihood of hypothesis 1
                 likelihood2, # likelihood of hypothesis 2
                 data, # data to use for the calculation
                 eps=1e-15 # epsilon for numerical stability
                 ):
    """Calculate Bayes factor for hypothesis 1 vs 2 given data."""
    likelihood1 = np.asarray(likelihood1)
    likelihood2 = np.asarray(likelihood2)
    
    # Validate inputs
    if len(likelihood1) != len(likelihood2):
        raise ValueError("Likelihood arrays must have same length")
    
    # For single observation
    if np.isscalar(data):
        if likelihood2[data] == 0:
            return np.inf if likelihood1[data] > 0 else np.nan
        return likelihood1[data] / likelihood2[data]
    
    # For multiple observations (assuming independence)
    # Use log-space computation for numerical stability
    log_bf = 0.0
    for obs in data:
        if likelihood2[obs] == 0:
            if likelihood1[obs] > 0:
                return np.inf  # Decisive evidence for H1
            else:
                return np.nan  # Both hypotheses say impossible
        
        if likelihood1[obs] == 0:
            return 0.0  # Decisive evidence for H2
        
        # Accumulate in log space
        log_bf += np.log(likelihood1[obs]) - np.log(likelihood2[obs])
    
    return np.exp(log_bf)

def interpret_bf(bf):
    "Interpret Bayes factor strength"
    if bf < 1/100:
        return "Decisive evidence against H1"
    elif bf < 1/10:
        return "Strong evidence against H1"
    elif bf < 1/3:
        return "Moderate evidence against H1"
    elif bf < 1:
        return "Weak evidence against H1"
    elif bf < 3:
        return "Weak evidence for H1"
    elif bf < 10:
        return "Moderate evidence for H1"
    elif bf < 100:
        return "Strong evidence for H1"
    else:
        return "Decisive evidence for H1"

# %% ../../nbs/rbe/01_bayes_core.ipynb 44
def beta_binomial_update(alpha, # prior alpha
                         beta, # prior beta
                         successes, # number of successes
                         failures # number of failures
                         ):
    "Update Beta prior with binomial data"
    return alpha + successes, beta + failures

# %% ../../nbs/rbe/01_bayes_core.ipynb 50
def normal_normal_update(prior_mean, prior_var, data_mean, data_var, n_obs):
    "Update Normal prior with Normal likelihood"
    # Precision weighting
    prior_prec = 1 / prior_var
    data_prec = n_obs / data_var
    
    post_prec = prior_prec + data_prec
    post_mean = (prior_prec * prior_mean + data_prec * data_mean) / post_prec
    post_var = 1 / post_prec
    
    return post_mean, post_var

# %% ../../nbs/rbe/01_bayes_core.ipynb 56
__all__ = [
    # Core updates
    'update', 'sequential',
    
    # Posterior predictive
    'predictive',
    
    # Model comparison
    'bayes_factor', 'interpret_bf',
    
    # Conjugate priors
    'beta_binomial_update', 'normal_normal_update'
]
