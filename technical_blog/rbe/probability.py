"""Core probability utilities for RBE - normalization, sampling, entropy, and divergence measures"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/rbe/00_probability.ipynb.

# %% auto 0
__all__ = ['normalize', 'sample', 'entropy', 'kl_div', 'js_div', 'eff_size', 'categorical', 'uniform', 'from_counts']

# %% ../../nbs/rbe/00_probability.ipynb 3
import numpy as np
from typing import Optional, Union, List
from fastcore.test import test_eq, test_close
from fastcore.all import *

# %% ../../nbs/rbe/00_probability.ipynb 5
def normalize(probs):
    "Normalize `probs` to sum to 1"
    probs = np.asarray(probs)
    s = np.sum(probs)
    if s == 0: raise ValueError("Cannot normalize zero probabilities")
    return probs / s

def sample(probs, n=1, rng=None):
    "Sample `n` indices from `probs` distribution"
    if rng is None: rng = np.random.default_rng()
    probs = np.asarray(probs)
    if np.any(probs < 0): raise ValueError("Probabilities must be non-negative")
    probs = normalize(probs)
    return rng.choice(len(probs), size=n, p=probs)

# %% ../../nbs/rbe/00_probability.ipynb 8
def entropy(probs, base=2):
    "Calculate entropy of `probs` distribution in given `base`"
    probs = normalize(probs)
    probs = probs[probs > 0]  # Remove zeros to avoid log(0)
    if base == 2:
        return -np.sum(probs * np.log2(probs))
    elif base == 'e':
        return -np.sum(probs * np.log(probs))
    else:
        return -np.sum(probs * np.log(probs)) / np.log(base)

def kl_div(p, q, eps=1e-10):
    "KL divergence from `q` to `p`"
    p, q = normalize(p), normalize(q)
    # Add epsilon to avoid log(0)
    return np.sum(p * np.log((p + eps) / (q + eps)))

def js_div(p, q):
    "Jensen-Shannon divergence between `p` and `q`"
    p, q = normalize(p), normalize(q)
    m = 0.5 * (p + q)
    return 0.5 * kl_div(p, m) + 0.5 * kl_div(q, m)

# %% ../../nbs/rbe/00_probability.ipynb 11
def eff_size(weights):
    "Calculate effective sample size of normalized `weights`"
    weights = normalize(weights)
    return 1.0 / np.sum(weights**2)

# %% ../../nbs/rbe/00_probability.ipynb 14
def categorical(probs, labels=None):
    "Create categorical distribution from `probs` with optional `labels`"
    probs = normalize(probs)
    if labels is None:
        labels = list(range(len(probs)))
    return dict(zip(labels, probs))

def uniform(n):
    "Create uniform distribution over `n` outcomes"
    return np.ones(n) / n

def from_counts(counts):
    "Create probability distribution from `counts`"
    counts = np.asarray(counts)
    if np.any(counts < 0):
        raise ValueError("Counts must be non-negative")
    return normalize(counts)

# %% ../../nbs/rbe/00_probability.ipynb 17
__all__ = [
    # Basic operations
    'normalize', 'sample',
    
    # Information measures
    'entropy', 'kl_div', 'js_div',
    
    # Effective sample size
    'eff_size',
    
    # Categorical utilities
    'categorical', 'uniform', 'from_counts'
]
