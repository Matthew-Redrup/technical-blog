"""Main recursive Bayesian estimator implementations with performance metrics"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/rbe/03_rbe_estimator.ipynb.

# %% auto 0
__all__ = ['estimate', 'adaptive', 'metrics', 'compare_online_batch', 'multi_model']

# %% ../../nbs/rbe/03_rbe_estimator.ipynb 3
import numpy as np
from typing import Optional, Callable, Dict, List, Tuple
from fastcore.test import test_eq, test_close
from fastcore.all import *
from .particle_filter import run as pf_run, init as pf_init, step as pf_step
from .probability import eff_size

# %% ../../nbs/rbe/03_rbe_estimator.ipynb 5
def estimate(observations, transition_fn, likelihood_fn, 
            n_particles=1000, init_fn=None, rng=None):
    "Main RBE estimator for `observations` with particle filter"
    return pf_run(observations, transition_fn, likelihood_fn,
                  n_particles, init_fn, rng=rng)

# %% ../../nbs/rbe/03_rbe_estimator.ipynb 8
def adaptive(observations, transition_fn, likelihood_fn, 
            adapt_fn=None, n_particles=1000, init_fn=None, rng=None):
    "Adaptive RBE estimator that adjusts parameters based on performance"
    if rng is None: rng = np.random.default_rng()
    if adapt_fn is None:
        # Default adaptation: adjust resampling threshold based on ESS
        def adapt_fn(ess_history, current_threshold):
            avg_ess = np.mean(ess_history[-5:]) if len(ess_history) >= 5 else ess_history[-1]
            if avg_ess < 0.3 * n_particles:
                return min(0.9, current_threshold + 0.1)
            elif avg_ess > 0.7 * n_particles:
                return max(0.1, current_threshold - 0.1)
            return current_threshold
    
    # Initialize
    state_dim = len(observations[0]) if hasattr(observations[0], '__len__') else 1
    particles, weights = pf_init(n_particles, state_dim, init_fn, rng)
    
    # Adaptive parameters
    resample_threshold = 0.5
    
    # Storage
    estimates = []
    ess_history = [eff_size(weights)]
    threshold_history = [resample_threshold]
    
    for obs in observations:
        # Adapt threshold
        resample_threshold = adapt_fn(ess_history, resample_threshold)
        threshold_history.append(resample_threshold)
        
        # Standard step with adaptive threshold
        particles, weights = pf_step(particles, weights, obs,
                                    transition_fn, likelihood_fn,
                                    resample_threshold, rng)
        
        # Record
        estimate = np.average(particles, weights=weights, axis=0)
        estimates.append(estimate)
        ess_history.append(eff_size(weights))
    
    return {
        'estimates': np.array(estimates),
        'ess_history': np.array(ess_history),
        'threshold_history': np.array(threshold_history),
        'final_particles': particles,
        'final_weights': weights
    }

# %% ../../nbs/rbe/03_rbe_estimator.ipynb 11
def metrics(true_states, estimates):
    "Calculate performance metrics for RBE estimates"
    true_states = np.array(true_states)
    estimates = np.array(estimates)
    
    # Ensure same shape
    if true_states.shape != estimates.shape:
        raise ValueError(f"Shape mismatch: true {true_states.shape} vs estimates {estimates.shape}")
    
    errors = true_states - estimates
    
    # Mean squared error
    mse = np.mean(errors**2)
    
    # Root mean squared error
    rmse = np.sqrt(mse)
    
    # Mean absolute error
    mae = np.mean(np.abs(errors))
    
    # Maximum absolute error
    max_ae = np.max(np.abs(errors))
    
    # Per-dimension metrics if multidimensional
    if errors.ndim > 1:
        dim_mse = np.mean(errors**2, axis=0)
        dim_rmse = np.sqrt(dim_mse)
        dim_mae = np.mean(np.abs(errors), axis=0)
    else:
        dim_mse = mse
        dim_rmse = rmse
        dim_mae = mae
    
    return {
        'mse': mse,
        'rmse': rmse,
        'mae': mae,
        'max_absolute_error': max_ae,
        'n_samples': len(estimates),
        'dim_mse': dim_mse,
        'dim_rmse': dim_rmse,
        'dim_mae': dim_mae
    }

# %% ../../nbs/rbe/03_rbe_estimator.ipynb 14
def compare_online_batch(observations, transition_fn, likelihood_fn,
                        n_particles=1000, rng=None):
    "Compare online (recursive) vs batch processing performance"
    if rng is None: rng = np.random.default_rng()
    
    # Online/recursive processing
    online_result = estimate(observations, transition_fn, likelihood_fn,
                            n_particles, rng=rng)
    
    # Batch processing (process all observations at once)
    # For particle filter, this means running forward-backward smoothing
    # Here we'll approximate with a simple batch mean for comparison
    state_dim = len(observations[0]) if hasattr(observations[0], '__len__') else 1
    particles, weights = pf_init(n_particles * 10, state_dim, rng=rng)  # More particles for batch
    
    # Apply all observations at once (simplified batch processing)
    for obs in observations:
        # Update weights based on all observations
        for i, particle in enumerate(particles):
            weights[i] *= likelihood_fn(particle, obs)
    
    weights = weights / np.sum(weights) if np.sum(weights) > 0 else np.ones_like(weights) / len(weights)
    batch_estimate = np.average(particles, weights=weights, axis=0)
    
    # For fair comparison, repeat batch estimate for all time steps
    batch_estimates = np.tile(batch_estimate, (len(observations), 1))
    
    return {
        'online': online_result,
        'batch': {
            'estimates': batch_estimates,
            'final_estimate': batch_estimate
        }
    }

# %% ../../nbs/rbe/03_rbe_estimator.ipynb 17
def multi_model(observations, models, model_probs=None, n_particles=1000, rng=None):
    "RBE with multiple competing models"
    if rng is None: rng = np.random.default_rng()
    n_models = len(models)
    
    if model_probs is None:
        model_probs = np.ones(n_models) / n_models
    
    # Run each model
    model_results = []
    model_likelihoods = []
    
    for model in models:
        result = estimate(observations, model['transition'], model['likelihood'],
                         n_particles // n_models, rng=rng)
        model_results.append(result)
        
        # Compute model likelihood (simplified - product of weights)
        likelihood = 1.0
        for weights in result['weights'][1:]:  # Skip initial
            likelihood *= np.mean(weights)  # Simplified
        model_likelihoods.append(likelihood)
    
    # Update model probabilities
    model_likelihoods = np.array(model_likelihoods)
    model_probs = model_probs * model_likelihoods
    model_probs = model_probs / np.sum(model_probs) if np.sum(model_probs) > 0 else np.ones(n_models) / n_models
    
    # Combine estimates using model probabilities
    combined_estimates = np.zeros_like(model_results[0]['estimates'])
    for i, (result, prob) in enumerate(zip(model_results, model_probs)):
        combined_estimates += prob * result['estimates']
    
    return {
        'estimates': combined_estimates,
        'model_probs': model_probs,
        'model_results': model_results
    }

# %% ../../nbs/rbe/03_rbe_estimator.ipynb 20
__all__ = [
    # Estimators
    'estimate', 'adaptive', 'multi_model',
    
    # Analysis
    'metrics', 'compare_online_batch'
]
