{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability\n",
    "\n",
    "> Core probability utilities for RBE - normalization, sampling, entropy, and divergence measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp rbe.probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewredrup/dev/technical-blog/.venv/lib/python3.13/site-packages/nbdev/doclinks.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources,importlib\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "from typing import Optional, Union, List\n",
    "from fastcore.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_eq, test_close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Operations\n",
    "\n",
    "Core probability operations following fast.ai style - short names, clear purpose.\n",
    "\n",
    "We write source code first, and then tests come after. The tests serve as both a means to confirm that the code works and also serves as working examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `normalize` function takes a list or array of numbers and converts them into proper probabilities that sum to 1.\n",
    "\n",
    "For example, if you have raw scores like `[1, 2, 3]`, it converts them to `[1/6, 2/6, 3/6]` = `[0.167, 0.333, 0.5]`.\n",
    "\n",
    "This is essential for probability calculations because:\n",
    "- Probabilities must sum to 1 by definition\n",
    "- Many algorithms (like sampling) require normalized distributions\n",
    "- Raw scores from sensors or models often aren't normalized\n",
    "\n",
    "The function also includes robust error handling for edge cases common in security applications - rejecting negative values, empty arrays, and all-zero inputs that could indicate data corruption or sensor failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def normalize(probs):\n",
    "    \"\"\"Normalize probabilities to sum to 1.\"\"\"\n",
    "    probs = np.asarray(probs, dtype=np.float64)  # Ensure float64 for precision\n",
    "    if probs.size == 0: raise ValueError(\"Cannot normalize empty array\")\n",
    "    if np.any(probs < 0): raise ValueError(\"Probabilities must be non-negative\") \n",
    "    s = np.sum(probs)\n",
    "    if s == 0: raise ValueError(\"Cannot normalize zero probabilities\")\n",
    "    return probs / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16666667, 0.33333333, 0.5       ])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test normalize function with comprehensive edge cases\n",
    "# Basic normalization\n",
    "probs = [1, 2, 3]\n",
    "normed = normalize(probs)\n",
    "test_close(np.sum(normed), 1.0)\n",
    "test_close(normed, [1/6, 2/6, 3/6])\n",
    "\n",
    "# Already normalized - should remain unchanged\n",
    "test_close(normalize([0.2, 0.3, 0.5]), [0.2, 0.3, 0.5])\n",
    "\n",
    "# Single element - critical for RBE edge cases\n",
    "test_close(normalize([5]), [1.0])\n",
    "\n",
    "# Uniform distribution\n",
    "test_close(normalize([1, 1, 1, 1]), [0.25, 0.25, 0.25, 0.25])\n",
    "\n",
    "# Very small numbers (numerical stability for anomaly scores)\n",
    "tiny = [1e-10, 2e-10, 3e-10]\n",
    "normed_tiny = normalize(tiny)\n",
    "test_close(np.sum(normed_tiny), 1.0)\n",
    "assert normed_tiny.dtype == np.float64, \"Should maintain float64 precision\"\n",
    "\n",
    "# Large numbers (overflow protection)\n",
    "large = [1e100, 2e100, 3e100]\n",
    "normed_large = normalize(large) \n",
    "test_close(np.sum(normed_large), 1.0)\n",
    "test_close(normed_large, [1/6, 2/6, 3/6])\n",
    "\n",
    "# Mixed scales (common in cyber security scores)\n",
    "mixed = [0.001, 1000, 0.1]\n",
    "normed_mixed = normalize(mixed)\n",
    "test_close(np.sum(normed_mixed), 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test error conditions\n",
    "# Empty array\n",
    "try:\n",
    "    normalize([])\n",
    "    assert False, \"Should raise ValueError for empty array\"\n",
    "except ValueError as e:\n",
    "    assert \"empty array\" in str(e)\n",
    "\n",
    "# All zeros\n",
    "try:\n",
    "    normalize([0, 0, 0])\n",
    "    assert False, \"Should raise ValueError for zero probabilities\"\n",
    "except ValueError as e:\n",
    "    assert \"zero probabilities\" in str(e)\n",
    "\n",
    "# Negative values (data corruption detection)\n",
    "try:\n",
    "    normalize([1, -2, 3])\n",
    "    assert False, \"Should raise ValueError for negative probabilities\"\n",
    "except ValueError as e:\n",
    "    assert \"non-negative\" in str(e)\n",
    "\n",
    "# NaN values (sensor failure detection)\n",
    "try:\n",
    "    normalize([1, np.nan, 3])\n",
    "    assert False, \"Should handle NaN gracefully\"\n",
    "except:\n",
    "    pass  # Expected to fail somehow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sample` function randomly selects indices from a probability distribution. \n",
    "\n",
    "Given a list of probabilities (like `[0.1, 0.7, 0.2]`), it returns random indices (0, 1, or 2) where higher probability values are more likely to be chosen. For example, index 1 would be selected about 70% of the time.\n",
    "\n",
    "Key features:\n",
    "- Takes any probabilities (automatically normalizes them to sum to 1)\n",
    "- Returns a single index when `n=1`, or an array of indices when `n>1`\n",
    "- Uses a controllable random number generator for reproducible results\n",
    "- Essential for Monte Carlo methods in Recursive Bayesian Estimators\n",
    "\n",
    "In your cyber security context, this would be useful for simulating network events based on their estimated probabilities or sampling from threat likelihood distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sample(probs, # probability distribution\n",
    "           n=1, # number of samples\n",
    "           rng=None # random number generator\n",
    "           ):\n",
    "    \"\"\"Sample indices from probability distribution.\"\"\"\n",
    "    if rng is None: rng = np.random.default_rng()\n",
    "    probs = normalize(probs)  # This handles all validation\n",
    "    if n == 1:\n",
    "        return rng.choice(len(probs), p=probs)  # Return scalar\n",
    "    else:\n",
    "        return rng.choice(len(probs), size=n, p=probs)  # Return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 1, 0, 2, 1, 1, 1, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample([0.1,0.7,0.2], n=10, rng=np.random.default_rng(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample([0.1,0.7,0.2], n=1, rng=np.random.default_rng(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sample function - critical for RBE Monte Carlo methods\n",
    "\n",
    "# Basic sampling with fixed seed for reproducibility\n",
    "rng = np.random.default_rng(42)\n",
    "samples = sample([0.1, 0.7, 0.2], n=1000, rng=rng)\n",
    "assert len(samples) == 1000\n",
    "assert np.all((samples >= 0) & (samples <= 2))\n",
    "\n",
    "# Check distribution approximates expected probabilities\n",
    "counts = np.bincount(samples, minlength=3)\n",
    "freqs = counts / 1000\n",
    "test_close(freqs, [0.1, 0.7, 0.2], eps=0.05)  # Allow 5% tolerance\n",
    "\n",
    "# Single sample returns scalar (not array)\n",
    "rng = np.random.default_rng(123)\n",
    "single = sample([0.3, 0.7], n=1, rng=rng)\n",
    "assert isinstance(single, (int, np.integer)), f\"Expected scalar, got {type(single)}\"\n",
    "assert 0 <= single <= 1\n",
    "\n",
    "# Multiple samples return array\n",
    "multiple = sample([0.3, 0.7], n=5, rng=rng)\n",
    "assert isinstance(multiple, np.ndarray), \"Expected array for n>1\"\n",
    "assert len(multiple) == 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with unnormalized probabilities (common in cyber security)\n",
    "unnorm = [10, 70, 20]  # Sums to 100, not 1\n",
    "rng = np.random.default_rng(456)\n",
    "samples = sample(unnorm, n=1000, rng=rng)\n",
    "counts = np.bincount(samples, minlength=3)\n",
    "freqs = counts / 1000\n",
    "test_close(freqs, [0.1, 0.7, 0.2], eps=0.05)\n",
    "\n",
    "# Edge case: single option (deterministic)\n",
    "certain = sample([1], n=10, rng=rng)\n",
    "assert np.all(certain == 0), \"Single option should always return index 0\"\n",
    "\n",
    "# Extreme probabilities (rare events in anomaly detection)\n",
    "rare = [0.999, 0.001]  # Very rare anomaly\n",
    "samples = sample(rare, n=10000, rng=np.random.default_rng(789))\n",
    "anomaly_count = np.sum(samples == 1)\n",
    "# Should be around 10 anomalies, allow wide tolerance for randomness\n",
    "assert 0 <= anomaly_count <= 50, f\"Got {anomaly_count} anomalies\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test error conditions for robust cyber security applications\n",
    "\n",
    "# Negative probabilities (corrupted threat scores)\n",
    "try:\n",
    "    sample([0.5, -0.3, 0.8], n=1)\n",
    "    assert False, \"Should reject negative probabilities\"\n",
    "except ValueError as e:\n",
    "    assert \"non-negative\" in str(e)\n",
    "\n",
    "# Empty probabilities\n",
    "try:\n",
    "    sample([], n=1)\n",
    "    assert False, \"Should reject empty probability array\"\n",
    "except ValueError as e:\n",
    "    assert \"empty array\" in str(e)\n",
    "\n",
    "# Zero sample count\n",
    "zero_samples = sample([0.5, 0.5], n=0)\n",
    "assert len(zero_samples) == 0, \"n=0 should return empty array\"\n",
    "\n",
    "# Test reproducibility (critical for security audits)\n",
    "rng1 = np.random.default_rng(999)\n",
    "rng2 = np.random.default_rng(999)\n",
    "s1 = sample([0.4, 0.6], n=100, rng=rng1)\n",
    "s2 = sample([0.4, 0.6], n=100, rng=rng2)\n",
    "assert np.array_equal(s1, s2), \"Same seed should produce identical results\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Measures\n",
    "\n",
    "Entropy and divergence measures for quantifying uncertainty and comparing distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def entropy(probs, base=2):\n",
    "    \"Calculate entropy of `probs` distribution in given `base`\"\n",
    "    probs = normalize(probs)\n",
    "    probs = probs[probs > 0]  # Remove zeros to avoid log(0)\n",
    "    if base == 2:\n",
    "        return -np.sum(probs * np.log2(probs))\n",
    "    elif base == 'e':\n",
    "        return -np.sum(probs * np.log(probs))\n",
    "    else:\n",
    "        return -np.sum(probs * np.log(probs)) / np.log(base)\n",
    "\n",
    "def kl_div(p, q, eps=1e-10):\n",
    "    \"KL divergence from `q` to `p`\"\n",
    "    p, q = normalize(p), normalize(q)\n",
    "    # Add epsilon to avoid log(0)\n",
    "    return np.sum(p * np.log((p + eps) / (q + eps)))\n",
    "\n",
    "def js_div(p, q):\n",
    "    \"Jensen-Shannon divergence between `p` and `q`\"\n",
    "    p, q = normalize(p), normalize(q)\n",
    "    m = 0.5 * (p + q)\n",
    "    return 0.5 * kl_div(p, m) + 0.5 * kl_div(q, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test entropy\n",
    "uniform = [0.5, 0.5]\n",
    "certain = [1.0, 0.0]\n",
    "assert entropy(uniform) > entropy(certain)\n",
    "test_close(entropy(uniform), 1.0)  # Maximum entropy for 2 outcomes\n",
    "\n",
    "# Test KL divergence\n",
    "p = [0.5, 0.5]\n",
    "q = [0.5, 0.5]\n",
    "test_close(kl_div(p, q), 0.0, eps=1e-10)  # Same distributions\n",
    "\n",
    "# Test JS divergence (symmetric)\n",
    "test_close(js_div(p, q), js_div(q, p))  # Should be symmetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effective Sample Size\n",
    "\n",
    "Measure of particle filter health - how many particles are effectively contributing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def eff_size(weights):\n",
    "    \"Calculate effective sample size of normalized `weights`\"\n",
    "    weights = normalize(weights)\n",
    "    return 1.0 / np.sum(weights**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test effective sample size\n",
    "uniform_weights = np.ones(100) / 100\n",
    "skewed_weights = np.zeros(100)\n",
    "skewed_weights[0] = 1.0\n",
    "\n",
    "test_close(eff_size(uniform_weights), 100.0)  # All particles contribute\n",
    "test_close(eff_size(skewed_weights), 1.0)     # Only one particle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Distribution Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def categorical(probs, labels=None):\n",
    "    \"Create categorical distribution from `probs` with optional `labels`\"\n",
    "    probs = normalize(probs)\n",
    "    if labels is None:\n",
    "        labels = list(range(len(probs)))\n",
    "    return dict(zip(labels, probs))\n",
    "\n",
    "def uniform(n):\n",
    "    \"Create uniform distribution over `n` outcomes\"\n",
    "    return np.ones(n) / n\n",
    "\n",
    "def from_counts(counts):\n",
    "    \"Create probability distribution from `counts`\"\n",
    "    counts = np.asarray(counts)\n",
    "    if np.any(counts < 0):\n",
    "        raise ValueError(\"Counts must be non-negative\")\n",
    "    return normalize(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test categorical utilities\n",
    "cat_dist = categorical([1, 2, 3], ['A', 'B', 'C'])\n",
    "test_eq(cat_dist['A'], 1/6)\n",
    "test_eq(cat_dist['B'], 2/6)\n",
    "test_eq(cat_dist['C'], 3/6)\n",
    "\n",
    "# Test uniform\n",
    "u = uniform(4)\n",
    "test_close(u, [0.25, 0.25, 0.25, 0.25])\n",
    "\n",
    "# Test from_counts\n",
    "probs = from_counts([10, 20, 30])\n",
    "test_close(probs, [1/6, 2/6, 3/6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "__all__ = [\n",
    "    # Basic operations\n",
    "    'normalize', 'sample',\n",
    "    \n",
    "    # Information measures\n",
    "    'entropy', 'kl_div', 'js_div',\n",
    "    \n",
    "    # Effective sample size\n",
    "    'eff_size',\n",
    "    \n",
    "    # Categorical utilities\n",
    "    'categorical', 'uniform', 'from_counts'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
