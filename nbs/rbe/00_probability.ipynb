{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability\n",
    "\n",
    "> Core probability utilities for RBE - normalization, sampling, entropy, and divergence measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp rbe.probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "from typing import Optional, Union, List\n",
    "from fastcore.all import *\n",
    "from scipy.special import entr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_eq, test_close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Operations\n",
    "\n",
    "Core probability operations following fast.ai style - short names, clear purpose.\n",
    "\n",
    "We write source code first, and then tests come after. The tests serve as both a means to confirm that the code works and also serves as working examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `normalize` function takes a list or array of numbers and converts them into proper probabilities that sum to 1.\n",
    "\n",
    "For example, if you have raw scores like `[1, 2, 3]`, it converts them to `[1/6, 2/6, 3/6]` = `[0.167, 0.333, 0.5]`.\n",
    "\n",
    "This is essential for probability calculations because:\n",
    "- Probabilities must sum to 1 by definition\n",
    "- Many algorithms (like sampling) require normalized distributions\n",
    "- Raw scores from sensors or models often aren't normalized\n",
    "\n",
    "The function also includes robust error handling for edge cases common in security applications - rejecting negative values, empty arrays, and all-zero inputs that could indicate data corruption or sensor failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def normalize(probs):\n",
    "    \"\"\"Normalize probabilities to sum to 1.\"\"\"\n",
    "    probs = np.asarray(probs, dtype=np.float64)  # Ensure float64 for precision\n",
    "    if probs.size == 0: raise ValueError(\"Cannot normalize empty array\")\n",
    "    if np.any(probs < 0): raise ValueError(\"Probabilities must be non-negative\") \n",
    "    s = np.sum(probs)\n",
    "    if s == 0: raise ValueError(\"Cannot normalize zero probabilities\")\n",
    "    return probs / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16666667, 0.33333333, 0.5       ])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test normalize function with comprehensive edge cases\n",
    "# Basic normalization\n",
    "probs = [1, 2, 3]\n",
    "normed = normalize(probs)\n",
    "test_close(np.sum(normed), 1.0)\n",
    "test_close(normed, [1/6, 2/6, 3/6])\n",
    "\n",
    "# Already normalized - should remain unchanged\n",
    "test_close(normalize([0.2, 0.3, 0.5]), [0.2, 0.3, 0.5])\n",
    "\n",
    "# Single element - critical for RBE edge cases\n",
    "test_close(normalize([5]), [1.0])\n",
    "\n",
    "# Uniform distribution\n",
    "test_close(normalize([1, 1, 1, 1]), [0.25, 0.25, 0.25, 0.25])\n",
    "\n",
    "# Very small numbers (numerical stability for anomaly scores)\n",
    "tiny = [1e-10, 2e-10, 3e-10]\n",
    "normed_tiny = normalize(tiny)\n",
    "test_close(np.sum(normed_tiny), 1.0)\n",
    "assert normed_tiny.dtype == np.float64, \"Should maintain float64 precision\"\n",
    "\n",
    "# Large numbers (overflow protection)\n",
    "large = [1e100, 2e100, 3e100]\n",
    "normed_large = normalize(large) \n",
    "test_close(np.sum(normed_large), 1.0)\n",
    "test_close(normed_large, [1/6, 2/6, 3/6])\n",
    "\n",
    "# Mixed scales (common in cyber security scores)\n",
    "mixed = [0.001, 1000, 0.1]\n",
    "normed_mixed = normalize(mixed)\n",
    "test_close(np.sum(normed_mixed), 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test error conditions\n",
    "# Empty array\n",
    "try:\n",
    "    normalize([])\n",
    "    assert False, \"Should raise ValueError for empty array\"\n",
    "except ValueError as e:\n",
    "    assert \"empty array\" in str(e)\n",
    "\n",
    "# All zeros\n",
    "try:\n",
    "    normalize([0, 0, 0])\n",
    "    assert False, \"Should raise ValueError for zero probabilities\"\n",
    "except ValueError as e:\n",
    "    assert \"zero probabilities\" in str(e)\n",
    "\n",
    "# Negative values (data corruption detection)\n",
    "try:\n",
    "    normalize([1, -2, 3])\n",
    "    assert False, \"Should raise ValueError for negative probabilities\"\n",
    "except ValueError as e:\n",
    "    assert \"non-negative\" in str(e)\n",
    "\n",
    "# NaN values (sensor failure detection)\n",
    "try:\n",
    "    normalize([1, np.nan, 3])\n",
    "    assert False, \"Should handle NaN gracefully\"\n",
    "except:\n",
    "    pass  # Expected to fail somehow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sample` function randomly selects indices from a probability distribution. \n",
    "\n",
    "Given a list of probabilities (like `[0.1, 0.7, 0.2]`), it returns random indices (0, 1, or 2) where higher probability values are more likely to be chosen. For example, index 1 would be selected about 70% of the time.\n",
    "\n",
    "Key features:\n",
    "- Takes any probabilities (automatically normalizes them to sum to 1)\n",
    "- Returns a single index when `n=1`, or an array of indices when `n>1`\n",
    "- Uses a controllable random number generator for reproducible results\n",
    "- Essential for Monte Carlo methods in Recursive Bayesian Estimators\n",
    "\n",
    "In your cyber security context, this would be useful for simulating network events based on their estimated probabilities or sampling from threat likelihood distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sample(probs, # probability distribution\n",
    "           n=1, # number of samples\n",
    "           rng=None # random number generator\n",
    "           ):\n",
    "    \"\"\"Sample indices from probability distribution.\"\"\"\n",
    "    if rng is None: rng = np.random.default_rng()\n",
    "    probs = normalize(probs)  # This handles all validation\n",
    "    if n == 1:\n",
    "        return rng.choice(len(probs), p=probs)  # Return scalar\n",
    "    else:\n",
    "        return rng.choice(len(probs), size=n, p=probs)  # Return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 1, 0, 2, 1, 1, 1, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample([0.1,0.7,0.2], n=10, rng=np.random.default_rng(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample([0.1,0.7,0.2], n=1, rng=np.random.default_rng(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sample function - critical for RBE Monte Carlo methods\n",
    "\n",
    "# Basic sampling with fixed seed for reproducibility\n",
    "rng = np.random.default_rng(42)\n",
    "samples = sample([0.1, 0.7, 0.2], n=1000, rng=rng)\n",
    "assert len(samples) == 1000\n",
    "assert np.all((samples >= 0) & (samples <= 2))\n",
    "\n",
    "# Check distribution approximates expected probabilities\n",
    "counts = np.bincount(samples, minlength=3)\n",
    "freqs = counts / 1000\n",
    "test_close(freqs, [0.1, 0.7, 0.2], eps=0.05)  # Allow 5% tolerance\n",
    "\n",
    "# Single sample returns scalar (not array)\n",
    "rng = np.random.default_rng(123)\n",
    "single = sample([0.3, 0.7], n=1, rng=rng)\n",
    "assert isinstance(single, (int, np.integer)), f\"Expected scalar, got {type(single)}\"\n",
    "assert 0 <= single <= 1\n",
    "\n",
    "# Multiple samples return array\n",
    "multiple = sample([0.3, 0.7], n=5, rng=rng)\n",
    "assert isinstance(multiple, np.ndarray), \"Expected array for n>1\"\n",
    "assert len(multiple) == 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with unnormalized probabilities (common in cyber security)\n",
    "unnorm = [10, 70, 20]  # Sums to 100, not 1\n",
    "rng = np.random.default_rng(456)\n",
    "samples = sample(unnorm, n=1000, rng=rng)\n",
    "counts = np.bincount(samples, minlength=3)\n",
    "freqs = counts / 1000\n",
    "test_close(freqs, [0.1, 0.7, 0.2], eps=0.05)\n",
    "\n",
    "# Edge case: single option (deterministic)\n",
    "certain = sample([1], n=10, rng=rng)\n",
    "assert np.all(certain == 0), \"Single option should always return index 0\"\n",
    "\n",
    "# Extreme probabilities (rare events in anomaly detection)\n",
    "rare = [0.999, 0.001]  # Very rare anomaly\n",
    "samples = sample(rare, n=10000, rng=np.random.default_rng(789))\n",
    "anomaly_count = np.sum(samples == 1)\n",
    "# Should be around 10 anomalies, allow wide tolerance for randomness\n",
    "assert 0 <= anomaly_count <= 50, f\"Got {anomaly_count} anomalies\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test error conditions for robust cyber security applications\n",
    "\n",
    "# Negative probabilities (corrupted threat scores)\n",
    "try:\n",
    "    sample([0.5, -0.3, 0.8], n=1)\n",
    "    assert False, \"Should reject negative probabilities\"\n",
    "except ValueError as e:\n",
    "    assert \"non-negative\" in str(e)\n",
    "\n",
    "# Empty probabilities\n",
    "try:\n",
    "    sample([], n=1)\n",
    "    assert False, \"Should reject empty probability array\"\n",
    "except ValueError as e:\n",
    "    assert \"empty array\" in str(e)\n",
    "\n",
    "# Zero sample count\n",
    "zero_samples = sample([0.5, 0.5], n=0)\n",
    "assert len(zero_samples) == 0, \"n=0 should return empty array\"\n",
    "\n",
    "# Test reproducibility (critical for security audits)\n",
    "rng1 = np.random.default_rng(999)\n",
    "rng2 = np.random.default_rng(999)\n",
    "s1 = sample([0.4, 0.6], n=100, rng=rng1)\n",
    "s2 = sample([0.4, 0.6], n=100, rng=rng2)\n",
    "assert np.array_equal(s1, s2), \"Same seed should produce identical results\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Measures\n",
    "\n",
    "**Entropy** and **divergence** measures for quantifying uncertainty and comparing distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy\n",
    "Entropy is a fundamental measure of uncertainty or randomness in information theory, our implementation uses it to quantify how \"spread out\" or unpredictable a probability distribution is.\n",
    "\n",
    "Our `entropy` function calculates Shannon entropy using the formula:\n",
    "\n",
    "$$H(X) = -∑ p(x) * log(p(x))$$\n",
    "\n",
    "\n",
    "Where:\n",
    "- $p(x)$ is the probability of each outcome\n",
    "- The sum is over all possible outcomes\n",
    "- The logarithm base determines the units (bits for base 2, nats for base e)\n",
    "\n",
    "Our implementation sneakily uses `scipy.special.entr(probs)`, which computes `x * log(x)` with proper handling of the edge case where `x = 0` (since `0 * log(0)` is mathematically defined as 0, not undefined).\n",
    "\n",
    "## What Entropy Measures\n",
    "\n",
    "Entropy quantifies uncertainty:\n",
    "\n",
    "- **High entropy** = high uncertainty = uniform distribution\n",
    "  - Example: `[0.25, 0.25, 0.25, 0.25]` has entropy = 2 bits\n",
    "  - All outcomes equally likely, maximum unpredictability\n",
    "\n",
    "- **Low entropy** = low uncertainty = skewed distribution  \n",
    "  - Example: `[0.8, 0.1, 0.1]` has lower entropy\n",
    "  - One outcome much more likely than others\n",
    "\n",
    "- **Zero entropy** = no uncertainty = deterministic\n",
    "  - Example: `[1.0, 0.0, 0.0]` has entropy = 0 bits\n",
    "  - Outcome is certain\n",
    "\n",
    "## Applications in Cyber Security\n",
    "\n",
    "For potential network anomaly detection, entropy is particularly valuable:\n",
    "\n",
    "1. **Baseline Characterization**: Measure the \"normal\" randomness of network traffic patterns\n",
    "2. **Anomaly Detection**: Sudden changes in entropy can indicate attacks or unusual behavior\n",
    "3. **Feature Engineering**: Use entropy of packet sizes, timing intervals, or connection patterns as input features\n",
    "4. **Model Uncertainty**: In Recursive Bayesian Estimators, entropy helps quantify how confident your predictions are\n",
    "\n",
    "For example, if network traffic normally has high entropy (many different packet sizes, destinations, etc.), but suddenly becomes very low entropy (repetitive patterns), this could signal a DDoS attack or malware communication.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def entropy(probs, # probability distribution\n",
    "            base=2 # base of the logarithm\n",
    "            ):\n",
    "    \"\"\"Calculate entropy using scipy's numerically stable implementation.\"\"\"\n",
    "    probs = normalize(probs)\n",
    "    h = np.sum(entr(probs))  # Uses x*log(x) with proper handling of x=0\n",
    "    \n",
    "    if base == 2:\n",
    "        return h / np.log(2)\n",
    "    elif base == 'e':\n",
    "        return h\n",
    "    else:\n",
    "        return h / np.log(base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy([0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test known entropy values\n",
    "# Binary uniform distribution has entropy = 1 bit\n",
    "test_close(entropy([0.5, 0.5]), 1.0)\n",
    "\n",
    "# Certain outcome has entropy = 0\n",
    "test_close(entropy([1.0, 0.0]), 0.0)\n",
    "test_close(entropy([0.0, 1.0]), 0.0)\n",
    "\n",
    "# 4-way uniform distribution has entropy = 2 bits\n",
    "test_close(entropy([0.25, 0.25, 0.25, 0.25]), 2.0)\n",
    "\n",
    "# Test different bases - CORRECTED\n",
    "uniform_binary = [0.5, 0.5]\n",
    "test_close(entropy(uniform_binary, base=2), 1.0)\n",
    "test_close(entropy(uniform_binary, base='e'), np.log(2))\n",
    "test_close(entropy(uniform_binary, base=10), np.log(2) / np.log(10))\n",
    "\n",
    "\n",
    "# Test with unnormalized probabilities (common in cyber security)\n",
    "test_close(entropy([1, 1]), 1.0)  # Should normalize to [0.5, 0.5]\n",
    "test_close(entropy([2, 2, 2, 2]), 2.0)  # Should normalize to uniform\n",
    "\n",
    "# Test numerical stability with tiny probabilities\n",
    "tiny_probs = [1e-15, 0.5, 0.5 - 1e-15]\n",
    "h_tiny = entropy(tiny_probs)\n",
    "test_close(h_tiny, 1.0, eps=1e-10)  # Should be close to uniform entropy\n",
    "\n",
    "# Test with zeros (scipy.special.entr handles this gracefully)\n",
    "with_zeros = [0.0, 0.3, 0.7]\n",
    "h_zeros = entropy(with_zeros)\n",
    "expected = entropy([0.3, 0.7])  # Should equal entropy without the zero\n",
    "test_close(h_zeros, expected)\n",
    "\n",
    "# Test entropy ordering (more uniform = higher entropy)\n",
    "certain = [1.0, 0.0, 0.0]\n",
    "skewed = [0.8, 0.1, 0.1] \n",
    "uniform = [1/3, 1/3, 1/3]\n",
    "\n",
    "h_certain = entropy(certain)\n",
    "h_skewed = entropy(skewed)\n",
    "h_uniform = entropy(uniform)\n",
    "\n",
    "assert h_certain < h_skewed < h_uniform, \"Entropy should increase with uniformity\"\n",
    "\n",
    "# Test large number of outcomes (network anomaly detection scenarios)\n",
    "many_outcomes = np.ones(100) / 100  # 100 equally likely events\n",
    "test_close(entropy(many_outcomes), np.log2(100))  # Should be log2(n) for uniform\n",
    "\n",
    "# Test edge cases for cyber security robustness\n",
    "single_outcome = [1.0]\n",
    "test_close(entropy(single_outcome), 0.0)\n",
    "\n",
    "# Test reproducibility\n",
    "h1 = entropy([0.4, 0.6])\n",
    "h2 = entropy([0.4, 0.6])\n",
    "assert h1 == h2, \"Entropy should be deterministic\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL Divergence\n",
    "\n",
    "KL divergence (Kullback-Leibler divergence) measures how different two probability distributions are. Think of it as asking: \"If I have distribution P, how surprised would I be if the world actually followed distribution Q instead?\"\n",
    "\n",
    "The mathematical formula is:\n",
    "$$D(P||Q) = \\sum p(x) \\cdot \\log\\left(\\frac{p(x)}{q(x)}\\right)$$\n",
    "\n",
    "## Intuitive Understanding\n",
    "\n",
    "Imagine you're a weather forecaster:\n",
    "- **P** is your forecast: \"80% chance of rain, 20% chance of sun\"  \n",
    "- **Q** is what actually happens over many days: \"60% rain, 40% sun\"\n",
    "\n",
    "KL divergence tells you how \"wrong\" your forecast was on average. If your forecast matches reality perfectly, KL divergence = 0. The more different they are, the higher the value.\n",
    "\n",
    "## Key Properties\n",
    "\n",
    "1. **Always non-negative**: KL divergence ≥ 0, with equality only when P = Q\n",
    "2. **Asymmetric**: D(P||Q) ≠ D(Q||P) in general - the direction matters!\n",
    "3. **Can be infinite**: When P assigns probability to something Q says is impossible\n",
    "\n",
    "## Why It's Important for Cyber Security Applications\n",
    "\n",
    "### 1. **Anomaly Detection**\n",
    "```python\n",
    "# Normal network traffic pattern\n",
    "normal_traffic = [0.7, 0.2, 0.1]  # [web, email, other]\n",
    "\n",
    "# Current traffic pattern  \n",
    "current_traffic = [0.3, 0.1, 0.6]  # Lots of \"other\" traffic - suspicious!\n",
    "\n",
    "# High KL divergence indicates anomaly\n",
    "anomaly_score = kl_div(current_traffic, normal_traffic)\n",
    "```\n",
    "\n",
    "### 2. **Model Drift Detection**\n",
    "Your RBE model learns what \"normal\" looks like. Over time, you can check if new data still matches your model's expectations:\n",
    "\n",
    "```python\n",
    "# Your model's learned distribution\n",
    "model_belief = [0.9, 0.08, 0.02]  # [normal, suspicious, attack]\n",
    "\n",
    "# New incoming data distribution\n",
    "recent_data = [0.7, 0.25, 0.05]   # More suspicious activity\n",
    "\n",
    "# KL divergence tells you if your model needs updating\n",
    "drift_score = kl_div(recent_data, model_belief)\n",
    "```\n",
    "\n",
    "### 3. **Information-Theoretic Security**\n",
    "KL divergence quantifies information leakage. If an attacker's observations P differ significantly from the expected distribution Q, it indicates potential information disclosure. (more on this at the end*)\n",
    "\n",
    "## Algorithm Walkthrough\n",
    "\n",
    "Our implementation handles several critical cases:\n",
    "\n",
    "1. **Normal case**: Computes the sum where both distributions have probability\n",
    "2. **Impossible events**: Returns infinity when P expects something Q says can't happen\n",
    "3. **Numerical stability**: Uses epsilon only when absolutely needed to avoid division by zero\n",
    "\n",
    "## Why Asymmetry Matters\n",
    "\n",
    "D(P||Q) asks: \"How surprised is P by Q?\"  \n",
    "D(Q||P) asks: \"How surprised is Q by P?\"\n",
    "\n",
    "In cyber security:\n",
    "- D(current||baseline) = \"How anomalous is current traffic compared to normal?\"\n",
    "- D(baseline||current) = \"How much would we need to update our normal baseline?\"\n",
    "\n",
    "These are fundamentally different questions! The first is better for anomaly detection, the second for model adaptation.\n",
    "\n",
    "The infinity case is particularly important - it means your current observations include events that your baseline model considers impossible, which is a strong anomaly signal in security contexts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def kl_div(p, # probability distribution\n",
    "           q, # probability distribution\n",
    "           eps=1e-15 # epsilon,small number to avoid log(0)\n",
    "           ):\n",
    "    \"\"\"KL divergence D(P||Q) from distribution P to distribution Q.\"\"\"\n",
    "    p, q = normalize(p), normalize(q)\n",
    "    # Check for undefined case: P has probability where Q doesn't\n",
    "    if np.any((p > 0) & (q == 0)): return np.inf\n",
    "    # Only use epsilon where both are zero (to handle 0*log(0) = 0)\n",
    "    mask = (p > 0)  # Only compute where p > 0\n",
    "    result = np.sum(p[mask] * np.log(p[mask] / np.maximum(q[mask], eps)))\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7515516053646771)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Anomaly Detection Example\n",
    "# Normal network traffic pattern\n",
    "normal_traffic = [0.7, 0.2, 0.1]  # [web, email, other]\n",
    "\n",
    "# Current traffic pattern  \n",
    "current_traffic = [0.3, 0.1, 0.6]  # Lots of \"other\" traffic - suspicious!\n",
    "\n",
    "# High KL divergence indicates anomaly\n",
    "anomaly_score = kl_div(current_traffic, normal_traffic)\n",
    "anomaly_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.15475300759416463)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model Drift Detection Example\n",
    "# Your model's learned distribution\n",
    "model_belief = [0.9, 0.08, 0.02]  # [normal, suspicious, attack]\n",
    "\n",
    "# New incoming data distribution\n",
    "recent_data = [0.7, 0.25, 0.05]   # More suspicious activity\n",
    "\n",
    "# KL divergence tells you if your model needs updating\n",
    "drift_score = kl_div(recent_data, model_belief)\n",
    "drift_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases for KL divergence\n",
    "\n",
    "# Identical distributions\n",
    "test_close(kl_div([0.5, 0.5], [0.5, 0.5]), 0.0, eps=1e-12)\n",
    "\n",
    "# Different distributions  \n",
    "p1, q1 = [0.8, 0.2], [0.6, 0.4]\n",
    "kl1 = kl_div(p1, q1)\n",
    "assert kl1 > 0, \"KL divergence should be positive for different distributions\"\n",
    "\n",
    "# Asymmetry: D(P||Q) ≠ D(Q||P)\n",
    "kl2 = kl_div(q1, p1)\n",
    "assert kl1 != kl2, \"KL divergence should be asymmetric\"\n",
    "\n",
    "# Undefined case: P has support where Q doesn't\n",
    "p_undefined = [0.5, 0.5, 0.0]\n",
    "q_undefined = [0.5, 0.0, 0.5]  # q[1]=0 but p[1]>0\n",
    "assert kl_div(p_undefined, q_undefined) == np.inf\n",
    "\n",
    "# Edge case: both zero at same positions (should work fine)\n",
    "p_zeros = [0.6, 0.4, 0.0]\n",
    "q_zeros = [0.7, 0.3, 0.0]\n",
    "finite_kl = kl_div(p_zeros, q_zeros)\n",
    "assert np.isfinite(finite_kl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JS Divergence\n",
    "\n",
    "Jensen-Shannon (JS) divergence is a powerful tool for measuring how different two probability distributions are, and it fixes several problems that KL divergence has. Let me break down how it works and why it's particularly valuable for your cyber security applications.\n",
    "\n",
    "#### How JS Divergence Works\n",
    "\n",
    "JS divergence uses a clever mathematical trick. Instead of directly comparing distributions P and Q, it:\n",
    "\n",
    "1. **Creates a mixture**: M = ½(P + Q) - the average of both distributions\n",
    "2. **Measures how each original distribution differs from this mixture**:\n",
    "   - KL(P || M) = how much P diverges from the average\n",
    "   - KL(Q || M) = how much Q diverges from the average  \n",
    "3. **Takes the average**: $JS(P,Q) = ½[KL(P||M) + KL(Q||M)]$\n",
    "\n",
    "Think of it like this: if two people disagree about something, JS divergence asks \"how much do they each disagree with a compromise position?\" rather than \"how much does person A disagree with person B?\"\n",
    "\n",
    "#### Key Advantages Over KL Divergence\n",
    "\n",
    "**1. Always Finite**: Unlike KL divergence, JS never returns infinity. This is crucial for robust cyber security systems where you can't have your anomaly detection crash on edge cases.\n",
    "\n",
    "**2. Symmetric**: JS(P,Q) = JS(Q,P). This means you get the same \"distance\" regardless of which distribution you consider the reference. Perfect for comparing network traffic patterns where neither is inherently the \"baseline.\"\n",
    "\n",
    "**3. Bounded**: JS divergence is always between 0 and log(2) ≈ 0.693. This gives you a natural scale - you know that 0.693 represents maximum possible difference, making it easier to set thresholds.\n",
    "\n",
    "**4. Smooth**: Small changes in probabilities lead to small changes in JS divergence, making it more stable for real-world noisy data.\n",
    "\n",
    "#### Why It's Useful for Cyber Security Applications\n",
    "\n",
    "**Robust Anomaly Detection**: Your network traffic analysis won't crash when encountering new, previously unseen traffic types (which would make KL divergence infinite).\n",
    "\n",
    "**Symmetric Threat Assessment**: When comparing current traffic to historical patterns, you get the same anomaly score regardless of which you treat as the \"reference\" - important for consistent alerting.\n",
    "\n",
    "**Natural Thresholds**: Since JS is bounded, you can establish meaningful thresholds like \"anything above 0.3 is suspicious, above 0.5 is likely an attack.\"\n",
    "\n",
    "**Comparative Analysis**: We can meaningfully compare how different various traffic patterns are from each other, not just from a baseline.\n",
    "\n",
    "For our Recursive Bayesian Estimator application, JS divergence gives us a stable, interpretable measure of how much our model's beliefs are changing over time - essential for detecting both gradual drift and sudden anomalies in network behavior.\n",
    "\n",
    "The mathematical elegance is that by using the mixture distribution M as an intermediate step, JS divergence captures the intuitive notion of \"distance between distributions\" while avoiding the mathematical pitfalls that make KL divergence problematic for practical applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def js_div(p, # probability distribution\n",
    "           q # probability distribution\n",
    "           ):\n",
    "    \"\"\"Jensen-Shannon divergence between distributions p and q.\"\"\"\n",
    "    p, q = normalize(p), normalize(q)\n",
    "    # Check dimensions match\n",
    "    if len(p) != len(q): raise ValueError(\"Distributions must have same length\")\n",
    "    \n",
    "    m = 0.5 * (p + q)\n",
    "    # JS divergence is always finite (unlike KL), but check for safety\n",
    "    kl_pm = kl_div(p, m)\n",
    "    kl_qm = kl_div(q, m)\n",
    "    \n",
    "    if not (np.isfinite(kl_pm) and np.isfinite(kl_qm)):\n",
    "        # This should never happen with proper implementation\n",
    "        raise RuntimeError(\"Unexpected infinite KL divergence in JS calculation\")\n",
    "    \n",
    "    return 0.5 * (kl_pm + kl_qm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the JS divergence function\n",
    "\n",
    "# Basic functionality tests\n",
    "# Identical distributions should give JS = 0\n",
    "test_close(js_div([0.5, 0.5], [0.5, 0.5]), 0.0, eps=1e-12)\n",
    "test_close(js_div([0.3, 0.4, 0.3], [0.3, 0.4, 0.3]), 0.0, eps=1e-12)\n",
    "\n",
    "# Different distributions should give JS > 0\n",
    "p1, q1 = [0.8, 0.2], [0.6, 0.4]\n",
    "js1 = js_div(p1, q1)\n",
    "assert js1 > 0, \"JS divergence should be positive for different distributions\"\n",
    "\n",
    "# Test symmetry: JS(P,Q) = JS(Q,P) - key advantage over KL\n",
    "js2 = js_div(q1, p1)\n",
    "test_close(js1, js2, eps=1e-12)\n",
    "\n",
    "# Test boundedness: JS divergence should be ≤ log(2) ≈ 0.693\n",
    "# Maximum occurs when distributions have disjoint support\n",
    "max_divergent = [1.0, 0.0], [0.0, 1.0]\n",
    "js_max = js_div(*max_divergent)\n",
    "test_close(js_max, np.log(2), eps=1e-10)\n",
    "assert js_max <= np.log(2) + 1e-10, \"JS divergence should be bounded by log(2)\"\n",
    "\n",
    "# Test with unnormalized inputs (common in cyber security)\n",
    "unnorm_p = [10, 20, 30]  # Will normalize to [1/6, 2/6, 3/6]\n",
    "unnorm_q = [15, 15, 30]  # Will normalize to [1/4, 1/4, 1/2]\n",
    "js_unnorm = js_div(unnorm_p, unnorm_q)\n",
    "# Should equal normalized version\n",
    "norm_p = [1/6, 2/6, 3/6]\n",
    "norm_q = [1/4, 1/4, 1/2]\n",
    "test_close(js_unnorm, js_div(norm_p, norm_q))\n",
    "\n",
    "# Test dimension mismatch error handling\n",
    "try:\n",
    "    js_div([0.5, 0.5], [0.3, 0.3, 0.4])\n",
    "    assert False, \"Should raise ValueError for mismatched dimensions\"\n",
    "except ValueError as e:\n",
    "    assert \"same length\" in str(e)\n",
    "\n",
    "# Test with zeros (should handle gracefully unlike KL)\n",
    "with_zeros_p = [0.6, 0.4, 0.0]\n",
    "with_zeros_q = [0.5, 0.0, 0.5]\n",
    "js_zeros = js_div(with_zeros_p, with_zeros_q)\n",
    "assert np.isfinite(js_zeros), \"JS divergence should be finite even with zeros\"\n",
    "assert js_zeros > 0, \"Different distributions with zeros should have positive JS\"\n",
    "\n",
    "# Test numerical stability with very small probabilities\n",
    "tiny_p = [1e-10, 0.5, 0.5 - 1e-10]\n",
    "tiny_q = [1e-10, 0.4, 0.6 - 1e-10]\n",
    "js_tiny = js_div(tiny_p, tiny_q)\n",
    "assert np.isfinite(js_tiny), \"Should handle tiny probabilities\"\n",
    "\n",
    "# Test single element distributions\n",
    "single_p = [1.0]\n",
    "single_q = [1.0]\n",
    "test_close(js_div(single_p, single_q), 0.0)\n",
    "\n",
    "# Test reproducibility\n",
    "js_rep1 = js_div([0.4, 0.6], [0.3, 0.7])\n",
    "js_rep2 = js_div([0.4, 0.6], [0.3, 0.7])\n",
    "assert js_rep1 == js_rep2, \"JS divergence should be deterministic\"\n",
    "\n",
    "# Cyber security scenario: compare traffic patterns\n",
    "normal_traffic = [0.7, 0.2, 0.1]      # [web, email, other]\n",
    "suspicious_traffic = [0.4, 0.1, 0.5]   # More \"other\" traffic\n",
    "attack_traffic = [0.1, 0.05, 0.85]     # Mostly \"other\" - likely attack\n",
    "\n",
    "js_suspicious = js_div(normal_traffic, suspicious_traffic)\n",
    "js_attack = js_div(normal_traffic, attack_traffic)\n",
    "\n",
    "# Attack should be more divergent than suspicious\n",
    "assert js_attack > js_suspicious, \"Attack pattern should be more divergent\"\n",
    "assert js_attack <= np.log(2), \"Even extreme patterns should be bounded\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effective Sample Size\n",
    "\n",
    "The `eff_size` function calculates the **effective sample size** of a set of weights, which is a crucial diagnostic tool in particle filtering and Monte Carlo methods. Let me break down what it does and why it may be important for our applications.\n",
    "\n",
    "### What It Measures\n",
    "\n",
    "The effective sample size tells you **how many particles are meaningfully contributing** to your estimate. It's calculated using the formula:\n",
    "\n",
    "$$N_{eff} = \\frac{1}{\\sum_{i=1}^N w_i^2}$$\n",
    "\n",
    "where $w_i$ are the normalized weights.\n",
    "\n",
    "### Intuitive Understanding\n",
    "\n",
    "Think of it this way: if you have 1000 particles but 999 of them have tiny weights and only 1 has a large weight, you're really only getting information from that 1 particle - your effective sample size is close to 1, not 1000.\n",
    "\n",
    "**Perfect case**: All particles have equal weight (1/N each)\n",
    "- Each weight = 1/N, so $w_i^2 = 1/N^2$\n",
    "- Sum of squares = $N \\times (1/N^2) = 1/N$\n",
    "- Effective size = $1/(1/N) = N$ ✓\n",
    "\n",
    "**Worst case**: One particle has all the weight\n",
    "- One weight = 1, others = 0\n",
    "- Sum of squares = $1^2 + 0 + 0 + ... = 1$\n",
    "- Effective size = $1/1 = 1$ ✓\n",
    "\n",
    "### Example Application for Cyber Security RBE\n",
    "\n",
    "#### 1. **Particle Filter Health Monitoring**\n",
    "```python\n",
    "# Your RBE is tracking network anomaly probabilities\n",
    "weights = [0.95, 0.02, 0.02, 0.01]  # Most belief in one hypothesis\n",
    "eff_size(weights)  # Returns ~1.1 - very low!\n",
    "```\n",
    "\n",
    "When effective sample size drops too low (common threshold: < N/2), it means your particle filter has **degeneracy** - most particles are irrelevant.\n",
    "\n",
    "#### 2. **Resampling Trigger**\n",
    "```python\n",
    "if eff_size(particle_weights) < len(particles) / 2:\n",
    "    # Time to resample! Most particles are useless\n",
    "    resample_particles()\n",
    "```\n",
    "\n",
    "This prevents your RBE from wasting computation on particles that don't contribute meaningful information about network threats.\n",
    "\n",
    "#### 3. **Quality Control**\n",
    "A consistently low effective sample size indicates:\n",
    "- Your model might be too confident (overconfident predictions)\n",
    "- You need more diverse particles\n",
    "- The observation model might be poorly calibrated\n",
    "\n",
    "#### 4. **Computational Efficiency**\n",
    "Instead of blindly using all N particles, you know you're really only getting information equivalent to `eff_size(weights)` particles. This helps you:\n",
    "- Decide when to add more particles\n",
    "- Understand the true precision of your estimates\n",
    "- Optimize computational resources\n",
    "\n",
    "### Example in Network Anomaly Detection\n",
    "\n",
    "```python\n",
    "# Scenario: RBE tracking different threat types\n",
    "threat_weights = [0.7, 0.15, 0.1, 0.05]  # [normal, suspicious, malware, APT]\n",
    "effective_particles = eff_size(threat_weights)  # ≈ 2.3\n",
    "\n",
    "# This tells you that despite having 4 categories, you're really only \n",
    "# getting information equivalent to ~2.3 independent observations\n",
    "# The \"normal\" category dominates, reducing diversity\n",
    "```\n",
    "\n",
    "### The Math Behind the Magic\n",
    "\n",
    "The formula $1/\\sum w_i^2$ is actually the **harmonic mean** of the reciprocals of the weights, which naturally penalizes uneven distributions:\n",
    "\n",
    "- When weights are uniform: harmonic mean ≈ arithmetic mean ≈ N\n",
    "- When weights are skewed: harmonic mean << arithmetic mean\n",
    "\n",
    "This makes it a sensitive detector of particle filter degeneracy, which is exactly what you want for maintaining a healthy RBE system in your cyber security application.\n",
    "\n",
    "The key insight is that effective sample size gives you a single number that summarizes the \"health\" of your particle distribution - essential for automated monitoring of your anomaly detection system!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def eff_size(weights):\n",
    "    \"Calculate effective sample size of normalized `weights`\"\n",
    "    weights = normalize(weights)\n",
    "    return 1.0 / np.sum(weights**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test effective sample size\n",
    "uniform_weights = np.ones(100) / 100\n",
    "skewed_weights = np.zeros(100)\n",
    "skewed_weights[0] = 1.0\n",
    "\n",
    "test_close(eff_size(uniform_weights), 100.0)  # All particles contribute\n",
    "test_close(eff_size(skewed_weights), 1.0)     # Only one particle\n",
    "\n",
    "# Test edge cases for particle filter robustness\n",
    "test_close(eff_size([1]), 1.0)  # Single particle\n",
    "test_close(eff_size([0.9, 0.1]), 1/(0.9**2 + 0.1**2))  # Known value\n",
    "\n",
    "# Test with unnormalized weights (common in practice)\n",
    "test_close(eff_size([10, 90]), eff_size([0.1, 0.9]))\n",
    "\n",
    "# Test numerical precision\n",
    "many_equal = np.ones(1000)\n",
    "test_close(eff_size(many_equal), 1000.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Distribution Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def categorical(probs, # probability distribution\n",
    "                labels=None # optional labels for the distribution\n",
    "                ):\n",
    "    \"Create categorical distribution from `probs` with optional `labels`\"\n",
    "    probs = normalize(probs)\n",
    "    if labels is None:\n",
    "        labels = list(range(len(probs)))\n",
    "    return dict(zip(labels, probs))\n",
    "\n",
    "def uniform(n):\n",
    "    \"Create uniform distribution over `n` outcomes\"\n",
    "    return np.ones(n) / n\n",
    "\n",
    "def from_counts(counts):\n",
    "    \"Create probability distribution from `counts`\"\n",
    "    counts = np.asarray(counts)\n",
    "    if np.any(counts < 0):\n",
    "        raise ValueError(\"Counts must be non-negative\")\n",
    "    return normalize(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test categorical utilities\n",
    "cat_dist = categorical([1, 2, 3], ['A', 'B', 'C'])\n",
    "test_eq(cat_dist['A'], 1/6)\n",
    "test_eq(cat_dist['B'], 2/6)\n",
    "test_eq(cat_dist['C'], 3/6)\n",
    "\n",
    "# Test uniform\n",
    "u = uniform(4)\n",
    "test_close(u, [0.25, 0.25, 0.25, 0.25])\n",
    "\n",
    "# Test from_counts\n",
    "probs = from_counts([10, 20, 30])\n",
    "test_close(probs, [1/6, 2/6, 3/6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "__all__ = [\n",
    "    # Basic operations\n",
    "    'normalize', 'sample',\n",
    "    \n",
    "    # Information measures\n",
    "    'entropy', 'kl_div', 'js_div',\n",
    "    \n",
    "    # Effective sample size\n",
    "    'eff_size',\n",
    "    \n",
    "    # Categorical utilities\n",
    "    'categorical', 'uniform', 'from_counts'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Didn't have time to look into this further but this sounds like an interesting application\n",
    "\n",
    "## Information-Theoretic Security with KL Divergence\n",
    "\n",
    "Information-theoretic security uses mathematical measures of information to detect and prevent security breaches. KL divergence is particularly powerful here because it quantifies how much information an adversary might be gaining.\n",
    "\n",
    "## Core Concept: Information Leakage\n",
    "\n",
    "In a secure system, an attacker's observations should look random or match expected patterns. When they deviate significantly, it suggests information is leaking.\n",
    "\n",
    "### Example: Timing Attack Detection\n",
    "\n",
    "```python\n",
    "# Normal response times (in milliseconds) for different operations\n",
    "normal_timing = [0.6, 0.3, 0.1]  # [fast, medium, slow operations]\n",
    "\n",
    "# Observed timing pattern during potential attack\n",
    "observed_timing = [0.2, 0.1, 0.7]  # Unusually many slow operations\n",
    "\n",
    "# High KL divergence suggests timing-based information leakage\n",
    "leakage_score = kl_div(observed_timing, normal_timing)\n",
    "```\n",
    "\n",
    "If an attacker is probing your system and causing unusual timing patterns (like forcing expensive cryptographic operations), the KL divergence will spike.\n",
    "\n",
    "## Practical Security Applications\n",
    "\n",
    "### 1. **Side-Channel Attack Detection**\n",
    "Monitor patterns in:\n",
    "- CPU usage during cryptographic operations\n",
    "- Memory access patterns \n",
    "- Network packet timing\n",
    "- Power consumption (in embedded systems)\n",
    "\n",
    "```python\n",
    "# Normal CPU usage distribution during encryption\n",
    "normal_cpu = [0.4, 0.4, 0.2]  # [low, medium, high usage]\n",
    "\n",
    "# During suspected side-channel attack\n",
    "attack_cpu = [0.1, 0.2, 0.7]   # Lots of high CPU usage\n",
    "\n",
    "# Detect the attack\n",
    "if kl_div(attack_cpu, normal_cpu) > threshold:\n",
    "    alert(\"Possible side-channel attack detected\")\n",
    "```\n",
    "\n",
    "### 2. **Covert Channel Detection**\n",
    "Attackers might hide communication in seemingly normal traffic patterns:\n",
    "\n",
    "```python\n",
    "# Normal distribution of packet sizes\n",
    "normal_packets = normalize([100, 200, 150, 50])  # Various normal sizes\n",
    "\n",
    "# Suspicious pattern - too regular, might encode data\n",
    "suspicious_packets = normalize([128, 128, 64, 128])  # Suspiciously regular\n",
    "\n",
    "# KL divergence reveals the anomaly\n",
    "covert_score = kl_div(suspicious_packets, normal_packets)\n",
    "```\n",
    "\n",
    "### 3. **Privacy-Preserving Systems**\n",
    "In differential privacy, you want to ensure that adding or removing one person's data doesn't significantly change query results:\n",
    "\n",
    "```python\n",
    "# Query results with person A's data\n",
    "with_person_a = [0.3, 0.4, 0.3]\n",
    "\n",
    "# Query results without person A's data  \n",
    "without_person_a = [0.32, 0.38, 0.3]\n",
    "\n",
    "# Low KL divergence means good privacy protection\n",
    "privacy_leakage = kl_div(with_person_a, without_person_a)\n",
    "```\n",
    "\n",
    "## Why KL Divergence is Perfect for This\n",
    "\n",
    "1. **Sensitive to small changes**: Even subtle information leakage creates measurable divergence\n",
    "2. **Asymmetric nature**: You can measure leakage in specific directions\n",
    "3. **Principled threshold setting**: Based on information theory rather than ad-hoc rules\n",
    "4. **Handles rare events**: The infinity case catches when attackers force impossible states\n",
    "\n",
    "## Advanced: Mutual Information Estimation\n",
    "\n",
    "KL divergence is also used to estimate mutual information between variables, which directly measures how much information one variable reveals about another:\n",
    "\n",
    "```python\n",
    "def mutual_info_estimate(joint_dist, marginal_x, marginal_y):\n",
    "    \"\"\"Estimate mutual information using KL divergence\"\"\"\n",
    "    # Product of marginals (independence assumption)\n",
    "    independent = np.outer(marginal_x, marginal_y).flatten()\n",
    "    \n",
    "    # KL divergence from independence to actual joint distribution\n",
    "    return kl_div(joint_dist.flatten(), independent)\n",
    "```\n",
    "\n",
    "This helps quantify exactly how much information an attacker gains from their observations.\n",
    "\n",
    "## Real-World Impact\n",
    "\n",
    "Information-theoretic security moves beyond \"did an attack happen?\" to \"how much information did the attacker gain?\" This quantitative approach enables:\n",
    "\n",
    "- **Risk quantification**: Measure actual information loss, not just binary breach/no-breach\n",
    "- **Proactive defense**: Detect information leakage before full compromise\n",
    "- **Privacy engineering**: Design systems with measurable privacy guarantees\n",
    "- **Forensic analysis**: Quantify the scope of information disclosure after incidents\n",
    "\n",
    "The beauty is that it's mathematically principled - you're not just looking for \"suspicious\" patterns, but measuring actual information flow using fundamental laws of information theory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
