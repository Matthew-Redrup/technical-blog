{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# RBE Part 1: Uncertainty Fundamentals\n",
    "\n",
    "> Understanding uncertainty in cybersecurity: types, mathematics, and practical applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp rbe.uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from fastcore.test import test_eq, test_close\n",
    "from fastcore.all import *\n",
    "from technical_blog.rbe.core import *\n",
    "from fasthtml.common import *\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Introduction: Why Uncertainty Matters in Cybersecurity\n",
    "\n",
    "In cybersecurity, we constantly make decisions under uncertainty. Consider these scenarios:\n",
    "\n",
    "1. **Network Anomaly Detection**: Is this unusual traffic pattern a cyberattack or normal variation?\n",
    "2. **Threat Intelligence**: How confident are we that this IP address is malicious?\n",
    "3. **Incident Response**: What's the probability this breach came from an insider threat?\n",
    "\n",
    "Traditional approaches often ignore uncertainty, leading to brittle systems that fail when conditions change. Recursive Bayesian Estimation (RBE) provides a principled framework for handling uncertainty that evolves over time.\n",
    "\n",
    "Let's start with a concrete example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Network intrusion detection uncertainty\n",
    "# We observe suspicious activity but aren't sure if it's an attack\n",
    "\n",
    "# Prior belief: 5% of network events are attacks\n",
    "prior_attack = 0.05\n",
    "prior_normal = 0.95\n",
    "prior = np.array([prior_attack, prior_normal])\n",
    "\n",
    "print(f\"Prior belief: {prior_attack*100:.1f}% chance of attack\")\n",
    "print(f\"Uncertainty (entropy): {prob_entropy(prior):.3f} bits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "This entropy measure tells us how uncertain we are. Higher entropy = more uncertainty. Now let's see how new evidence changes our beliefs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New evidence: unusual port scanning detected\n",
    "# Likelihood: attacks cause port scanning 90% of the time\n",
    "#            normal traffic causes it 10% of the time\n",
    "likelihood = np.array([0.9, 0.1])  # [P(evidence|attack), P(evidence|normal)]\n",
    "\n",
    "# Update beliefs using Bayes' theorem\n",
    "posterior = bayes_update(prior, likelihood)\n",
    "\n",
    "print(f\"After observing port scanning:\")\n",
    "print(f\"Updated belief: {posterior[0]*100:.1f}% chance of attack\")\n",
    "print(f\"New uncertainty: {prob_entropy(posterior):.3f} bits\")\n",
    "print(f\"Uncertainty reduction: {prob_entropy(prior) - prob_entropy(posterior):.3f} bits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "Notice how the evidence both **increased our confidence** in an attack and **reduced our uncertainty**. This is the essence of Bayesian reasoning - we start with prior beliefs and update them as we gather evidence.\n",
    "\n",
    "## Types of Uncertainty\n",
    "\n",
    "Understanding uncertainty requires distinguishing between two fundamental types:\n",
    "\n",
    "### Aleatory Uncertainty (Irreducible)\n",
    "**Inherent randomness** in the system that cannot be reduced by gathering more data.\n",
    "\n",
    "**Cybersecurity Examples:**\n",
    "- Random timing of legitimate user logins\n",
    "- Network packet loss due to congestion\n",
    "- Attacker's choice of target systems\n",
    "\n",
    "### Epistemic Uncertainty (Reducible)\n",
    "**Lack of knowledge** that can be reduced by collecting more information.\n",
    "\n",
    "**Cybersecurity Examples:**\n",
    "- Unknown attack signatures\n",
    "- Incomplete threat intelligence\n",
    "- Uncertain system configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def demo_uncertainty_types(n_samples=1000, rng=None):\n",
    "    \"\"\"Demonstrate aleatory vs epistemic uncertainty with cybersecurity examples\"\"\"\n",
    "    if rng is None: rng = np.random.default_rng(42)\n",
    "    \n",
    "    # Aleatory: Login times follow a random distribution (irreducible)\n",
    "    # Even if we know the distribution perfectly, individual login times are unpredictable\n",
    "    login_times = rng.exponential(scale=2.0, size=n_samples)  # Hours between logins\n",
    "    \n",
    "    # Epistemic: Attack probability depends on unknown threat level (reducible)\n",
    "    # As we gather more intelligence, we can better estimate the true threat level\n",
    "    true_threat_level = 0.3  # Unknown to us initially\n",
    "    \n",
    "    # Our epistemic uncertainty: we think threat level is between 0.1 and 0.5\n",
    "    epistemic_samples = rng.uniform(0.1, 0.5, size=n_samples)\n",
    "    \n",
    "    return {\n",
    "        'aleatory': login_times,\n",
    "        'epistemic': epistemic_samples,\n",
    "        'true_threat': true_threat_level\n",
    "    }\n",
    "\n",
    "# Demonstrate the difference\n",
    "uncertainty_demo = demo_uncertainty_types()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Aleatory uncertainty: login time distribution\n",
    "ax1.hist(uncertainty_demo['aleatory'], bins=50, alpha=0.7, color='blue')\n",
    "ax1.set_title('Aleatory Uncertainty\\n(Login Time Distribution)')\n",
    "ax1.set_xlabel('Hours Between Logins')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.text(0.02, 0.98, 'Irreducible:\\nInherent randomness', \n",
    "         transform=ax1.transAxes, va='top', bbox=dict(boxstyle='round', facecolor='lightblue'))\n",
    "\n",
    "# Epistemic uncertainty: our belief about threat level\n",
    "ax2.hist(uncertainty_demo['epistemic'], bins=50, alpha=0.7, color='red')\n",
    "ax2.axvline(uncertainty_demo['true_threat'], color='black', linestyle='--', linewidth=2, label='True Value')\n",
    "ax2.set_title('Epistemic Uncertainty\\n(Threat Level Estimate)')\n",
    "ax2.set_xlabel('Estimated Threat Level')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.legend()\n",
    "ax2.text(0.02, 0.98, 'Reducible:\\nLack of knowledge', \n",
    "         transform=ax2.transAxes, va='top', bbox=dict(boxstyle='round', facecolor='lightcoral'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Aleatory uncertainty (login times): mean={np.mean(uncertainty_demo['aleatory']):.2f} hours\")\n",
    "print(f\"Epistemic uncertainty range: {np.min(uncertainty_demo['epistemic']):.2f} to {np.max(uncertainty_demo['epistemic']):.2f}\")\n",
    "print(f\"True threat level: {uncertainty_demo['true_threat']} (unknown to us initially)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "**Key Insight**: RBE excels at handling epistemic uncertainty. As we collect more evidence, our beliefs converge toward the truth. Aleatory uncertainty remains, but we can quantify and account for it.\n",
    "\n",
    "## Mathematical Foundations\n",
    "\n",
    "Let's build our mathematical toolkit using the core functions. We'll start with probability distributions and work toward Bayesian inference.\n",
    "\n",
    "### Probability Distributions and Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def explore_distributions():\n",
    "    \"\"\"Interactive exploration of probability distributions and entropy\"\"\"\n",
    "    \n",
    "    # Different types of distributions with cybersecurity interpretations\n",
    "    distributions = {\n",
    "        'Uniform (Maximum Uncertainty)': [0.25, 0.25, 0.25, 0.25],\n",
    "        'Slightly Informed': [0.4, 0.3, 0.2, 0.1],\n",
    "        'Confident': [0.7, 0.2, 0.08, 0.02],\n",
    "        'Certain': [0.95, 0.03, 0.01, 0.01]\n",
    "    }\n",
    "    \n",
    "    labels = ['Benign', 'Suspicious', 'Malicious', 'Critical']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    entropies = []\n",
    "    \n",
    "    for i, (name, probs) in enumerate(distributions.items()):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Bar chart of probabilities\n",
    "        bars = ax.bar(labels, probs, alpha=0.7, \n",
    "                     color=['green', 'yellow', 'orange', 'red'])\n",
    "        \n",
    "        # Calculate entropy\n",
    "        entropy = prob_entropy(probs)\n",
    "        entropies.append(entropy)\n",
    "        \n",
    "        ax.set_title(f'{name}\\nEntropy: {entropy:.3f} bits')\n",
    "        ax.set_ylabel('Probability')\n",
    "        ax.set_ylim(0, 1)\n",
    "        \n",
    "        # Add probability values on bars\n",
    "        for bar, prob in zip(bars, probs):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                   f'{prob:.2f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return distributions, entropies\n",
    "\n",
    "# Explore different distributions\n",
    "dists, entropies = explore_distributions()\n",
    "\n",
    "print(\"\\nEntropy Analysis:\")\n",
    "for (name, _), entropy in zip(dists.items(), entropies):\n",
    "    print(f\"{name}: {entropy:.3f} bits\")\n",
    "    \n",
    "print(f\"\\nMaximum possible entropy (uniform): {np.log2(4):.3f} bits\")\n",
    "print(f\"Minimum possible entropy (certain): 0.000 bits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "**Entropy Interpretation:**\n",
    "- **High entropy** (uniform): We're completely uncertain about the threat level\n",
    "- **Low entropy** (certain): We're confident in our assessment\n",
    "- **Information gain**: Entropy reduction when we receive evidence\n",
    "\n",
    "### Bayes' Theorem in Action\n",
    "\n",
    "Now let's see how Bayes' theorem works in practice for cybersecurity scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def bayesian_intrusion_detection(n_observations=10, rng=None):\n",
    "    \"\"\"Demonstrate Bayesian updating for intrusion detection\"\"\"\n",
    "    if rng is None: rng = np.random.default_rng(42)\n",
    "    \n",
    "    # Prior: Start with low suspicion\n",
    "    prior = np.array([0.05, 0.95])  # [attack, normal]\n",
    "    \n",
    "    # Define evidence types and their likelihoods\n",
    "    evidence_types = {\n",
    "        'port_scan': np.array([0.8, 0.1]),      # Strong indicator of attack\n",
    "        'failed_login': np.array([0.7, 0.3]),   # Moderate indicator\n",
    "        'data_transfer': np.array([0.6, 0.4]),  # Weak indicator\n",
    "        'normal_traffic': np.array([0.1, 0.9])  # Counter-evidence\n",
    "    }\n",
    "    \n",
    "    # Simulate sequence of observations\n",
    "    observations = rng.choice(list(evidence_types.keys()), size=n_observations, \n",
    "                             p=[0.1, 0.2, 0.3, 0.4])  # Mostly normal traffic\n",
    "    \n",
    "    # Track evolution of beliefs\n",
    "    belief_history = [prior.copy()]\n",
    "    posterior = prior.copy()\n",
    "    \n",
    "    print(\"Bayesian Intrusion Detection Sequence:\")\n",
    "    print(f\"Initial belief: {posterior[0]*100:.1f}% attack probability\\n\")\n",
    "    \n",
    "    for i, obs in enumerate(observations):\n",
    "        likelihood = evidence_types[obs]\n",
    "        posterior = bayes_update(posterior, likelihood)\n",
    "        belief_history.append(posterior.copy())\n",
    "        \n",
    "        print(f\"Step {i+1}: Observed '{obs}'\")\n",
    "        print(f\"  Likelihood: [attack={likelihood[0]:.1f}, normal={likelihood[1]:.1f}]\")\n",
    "        print(f\"  Updated belief: {posterior[0]*100:.1f}% attack probability\")\n",
    "        print(f\"  Uncertainty: {prob_entropy(posterior):.3f} bits\\n\")\n",
    "    \n",
    "    return np.array(belief_history), observations\n",
    "\n",
    "# Run the demonstration\n",
    "beliefs, obs_sequence = bayesian_intrusion_detection()\n",
    "\n",
    "# Visualize the evolution of beliefs\n",
    "fig, ax = viz_beliefs(beliefs[:, 0], title='Attack Probability Over Time', \n",
    "                      figsize=(10, 6))\n",
    "ax.set_ylabel('Attack Probability')\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "# Add observation labels\n",
    "for i, obs in enumerate(obs_sequence):\n",
    "    ax.annotate(obs, (i+1, beliefs[i+1, 0]), \n",
    "                xytext=(5, 5), textcoords='offset points', \n",
    "                fontsize=8, alpha=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "**Key Observations:**\n",
    "1. **Sequential updating**: Each piece of evidence refines our beliefs\n",
    "2. **Evidence strength matters**: Port scans have bigger impact than normal traffic\n",
    "3. **Counter-evidence**: Normal traffic observations reduce attack probability\n",
    "4. **Uncertainty tracking**: We can quantify how confident we are\n",
    "\n",
    "### Handling Multiple Hypotheses\n",
    "\n",
    "In real cybersecurity scenarios, we often consider multiple threat types simultaneously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def multi_threat_assessment(rng=None):\n",
    "    \"\"\"Demonstrate multi-hypothesis threat assessment\"\"\"\n",
    "    if rng is None: rng = np.random.default_rng(42)\n",
    "    \n",
    "    # Multiple threat types\n",
    "    threats = ['Benign', 'Insider', 'External', 'APT']\n",
    "    \n",
    "    # Prior beliefs (start with mostly benign assumption)\n",
    "    prior = np.array([0.85, 0.05, 0.08, 0.02])\n",
    "    \n",
    "    # Evidence and likelihood matrices\n",
    "    evidence_scenarios = {\n",
    "        'After hours access': np.array([0.1, 0.7, 0.3, 0.4]),\n",
    "        'External IP connection': np.array([0.2, 0.1, 0.8, 0.6]),\n",
    "        'Privilege escalation': np.array([0.05, 0.6, 0.7, 0.9]),\n",
    "        'Data exfiltration': np.array([0.01, 0.4, 0.8, 0.95]),\n",
    "        'Stealth techniques': np.array([0.02, 0.2, 0.5, 0.9])\n",
    "    }\n",
    "    \n",
    "    # Simulate evidence sequence\n",
    "    evidence_sequence = ['After hours access', 'External IP connection', 'Privilege escalation']\n",
    "    \n",
    "    # Track belief evolution\n",
    "    beliefs = [prior.copy()]\n",
    "    current_belief = prior.copy()\n",
    "    \n",
    "    print(\"Multi-Threat Assessment:\")\n",
    "    print(\"\\nInitial Assessment:\")\n",
    "    for i, threat in enumerate(threats):\n",
    "        print(f\"  {threat}: {current_belief[i]*100:.1f}%\")\n",
    "    print(f\"  Uncertainty: {prob_entropy(current_belief):.3f} bits\")\n",
    "    \n",
    "    # Process evidence sequence\n",
    "    for evidence in evidence_sequence:\n",
    "        likelihood = evidence_scenarios[evidence]\n",
    "        current_belief = bayes_update(current_belief, likelihood)\n",
    "        beliefs.append(current_belief.copy())\n",
    "        \n",
    "        print(f\"\\nAfter observing: {evidence}\")\n",
    "        for i, threat in enumerate(threats):\n",
    "            print(f\"  {threat}: {current_belief[i]*100:.1f}%\")\n",
    "        print(f\"  Uncertainty: {prob_entropy(current_belief):.3f} bits\")\n",
    "    \n",
    "    return np.array(beliefs), threats, evidence_sequence\n",
    "\n",
    "# Run multi-threat assessment\n",
    "threat_beliefs, threat_types, evidence_seq = multi_threat_assessment()\n",
    "\n",
    "# Visualize evolution of all threat probabilities\n",
    "fig, ax = viz_beliefs(threat_beliefs, labels=threat_types, \n",
    "                      title='Multi-Threat Probability Evolution', figsize=(12, 6))\n",
    "\n",
    "# Add evidence markers\n",
    "for i, evidence in enumerate(evidence_seq):\n",
    "    ax.axvline(i+1, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax.text(i+1, ax.get_ylim()[1]*0.9, evidence, \n",
    "            rotation=45, ha='right', va='top', fontsize=9)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Interactive Uncertainty Explorer\n",
    "\n",
    "Let's create an interactive component to explore how different evidence affects our beliefs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_uncertainty_calculator():\n",
    "    \"\"\"Create an interactive uncertainty calculator using FastHTML\"\"\"\n",
    "    \n",
    "    def uncertainty_form():\n",
    "        return Form(\n",
    "            Div(\n",
    "                H3(\"Bayesian Uncertainty Calculator\"),\n",
    "                P(\"Explore how evidence changes beliefs and uncertainty\"),\n",
    "                cls=\"mb-4\"\n",
    "            ),\n",
    "            \n",
    "            # Prior beliefs input\n",
    "            Div(\n",
    "                Label(\"Prior Belief (Attack Probability):\"),\n",
    "                Input(type=\"range\", name=\"prior\", min=\"0\", max=\"100\", value=\"5\", \n",
    "                      id=\"prior-slider\", cls=\"w-full\"),\n",
    "                Span(id=\"prior-value\", cls=\"text-sm text-gray-600\"),\n",
    "                cls=\"mb-4\"\n",
    "            ),\n",
    "            \n",
    "            # Evidence strength input\n",
    "            Div(\n",
    "                Label(\"Evidence Strength (Likelihood Ratio):\"),\n",
    "                Input(type=\"range\", name=\"evidence\", min=\"1\", max=\"10\", value=\"5\", \n",
    "                      id=\"evidence-slider\", cls=\"w-full\"),\n",
    "                Span(id=\"evidence-value\", cls=\"text-sm text-gray-600\"),\n",
    "                cls=\"mb-4\"\n",
    "            ),\n",
    "            \n",
    "            # Results display\n",
    "            Div(\n",
    "                Div(id=\"calculation-results\", cls=\"p-4 bg-gray-100 rounded\"),\n",
    "                cls=\"mb-4\"\n",
    "            ),\n",
    "            \n",
    "            # JavaScript for interactivity\n",
    "            Script(\"\"\"\n",
    "            function updateCalculation() {\n",
    "                const prior = document.getElementById('prior-slider').value / 100;\n",
    "                const evidence = document.getElementById('evidence-slider').value;\n",
    "                \n",
    "                document.getElementById('prior-value').textContent = (prior * 100).toFixed(1) + '%';\n",
    "                document.getElementById('evidence-value').textContent = evidence + 'x';\n",
    "                \n",
    "                // Calculate posterior using Bayes' theorem\n",
    "                const likelihood = evidence;\n",
    "                const posterior = (prior * likelihood) / (prior * likelihood + (1 - prior));\n",
    "                \n",
    "                // Calculate entropy (simplified)\n",
    "                const priorEntropy = prior === 0 || prior === 1 ? 0 : \n",
    "                    -(prior * Math.log2(prior) + (1-prior) * Math.log2(1-prior));\n",
    "                const posteriorEntropy = posterior === 0 || posterior === 1 ? 0 : \n",
    "                    -(posterior * Math.log2(posterior) + (1-posterior) * Math.log2(1-posterior));\n",
    "                \n",
    "                const infoGain = priorEntropy - posteriorEntropy;\n",
    "                \n",
    "                document.getElementById('calculation-results').innerHTML = `\n",
    "                    <h4>Results:</h4>\n",
    "                    <p><strong>Prior:</strong> ${(prior * 100).toFixed(1)}% attack probability</p>\n",
    "                    <p><strong>Posterior:</strong> ${(posterior * 100).toFixed(1)}% attack probability</p>\n",
    "                    <p><strong>Prior Uncertainty:</strong> ${priorEntropy.toFixed(3)} bits</p>\n",
    "                    <p><strong>Posterior Uncertainty:</strong> ${posteriorEntropy.toFixed(3)} bits</p>\n",
    "                    <p><strong>Information Gain:</strong> ${infoGain.toFixed(3)} bits</p>\n",
    "                `;\n",
    "            }\n",
    "            \n",
    "            document.getElementById('prior-slider').addEventListener('input', updateCalculation);\n",
    "            document.getElementById('evidence-slider').addEventListener('input', updateCalculation);\n",
    "            updateCalculation(); // Initial calculation\n",
    "            \"\"\")\n",
    "        )\n",
    "    \n",
    "    return uncertainty_form()\n",
    "\n",
    "# Display the interactive calculator\n",
    "print(\"Interactive Uncertainty Calculator:\")\n",
    "print(\"(This would be rendered as interactive HTML in the FastHTML app)\")\n",
    "print(\"\\nFeatures:\")\n",
    "print(\"- Adjust prior belief with slider\")\n",
    "print(\"- Change evidence strength\")\n",
    "print(\"- See real-time Bayesian updates\")\n",
    "print(\"- Track uncertainty reduction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Summary: Key Takeaways\n",
    "\n",
    "We've explored the fundamentals of uncertainty in cybersecurity through the lens of Bayesian reasoning:\n",
    "\n",
    "### Core Concepts\n",
    "1. **Two Types of Uncertainty**:\n",
    "   - **Aleatory** (irreducible): Inherent randomness in systems\n",
    "   - **Epistemic** (reducible): Our lack of knowledge\n",
    "\n",
    "2. **Entropy as Uncertainty Measure**:\n",
    "   - Quantifies how uncertain we are about outcomes\n",
    "   - Information gain = entropy reduction\n",
    "\n",
    "3. **Bayesian Updating**:\n",
    "   - Start with prior beliefs\n",
    "   - Update with evidence using Bayes' theorem\n",
    "   - Track uncertainty throughout the process\n",
    "\n",
    "### Practical Applications\n",
    "- **Network intrusion detection** with evolving threat assessments\n",
    "- **Multi-hypothesis testing** for different attack types\n",
    "- **Evidence accumulation** over time\n",
    "- **Uncertainty quantification** for decision making\n",
    "\n",
    "### Next Steps\n",
    "In the next notebook, we'll explore how to implement these concepts using **Recursive Bayesian Estimation** with particle filters for real-time cybersecurity applications.\n",
    "\n",
    "The mathematical foundation we've built here provides the basis for more sophisticated techniques that can handle:\n",
    "- Non-linear system dynamics\n",
    "- Multi-dimensional state spaces\n",
    "- Continuous-time observations\n",
    "- Adaptive learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "__all__ = [\n",
    "    'demo_uncertainty_types',\n",
    "    'explore_distributions', \n",
    "    'bayesian_intrusion_detection',\n",
    "    'multi_threat_assessment',\n",
    "    'create_uncertainty_calculator'\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
