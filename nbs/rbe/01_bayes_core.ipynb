{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Core\n",
    "\n",
    "> Core Bayesian inference functions - updates, sequential processing, and posterior predictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp rbe.bayes_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "from typing import Optional, Union, List, Callable\n",
    "from fastcore.test import test_eq, test_close\n",
    "from fastcore.all import *\n",
    "from technical_blog.rbe.probability import normalize, sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Bayesian Updates\n",
    "\n",
    "The heart of Bayesian inference - updating beliefs with evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def update(prior, likelihood, evidence=None):\n",
    "    \"Update `prior` with `likelihood` and optional `evidence`\"\n",
    "    prior, likelihood = np.array(prior), np.array(likelihood)\n",
    "    if evidence is None: evidence = (prior * likelihood).sum()\n",
    "    if evidence == 0: raise ValueError(\"Impossible observation\")\n",
    "    return (prior * likelihood) / evidence\n",
    "\n",
    "def sequential(priors, likelihoods, evidences=None):\n",
    "    \"Sequential updating of `priors` with `likelihoods`\"\n",
    "    if evidences is None:\n",
    "        evidences = [None] * len(likelihoods)\n",
    "    \n",
    "    posterior = np.array(priors)\n",
    "    posteriors = [posterior.copy()]\n",
    "    \n",
    "    for likelihood, evidence in zip(likelihoods, evidences):\n",
    "        posterior = update(posterior, likelihood, evidence)\n",
    "        posteriors.append(posterior.copy())\n",
    "    \n",
    "    return np.array(posteriors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Bayesian updates\n",
    "prior = np.array([0.3, 0.7])\n",
    "likelihood = np.array([0.8, 0.2])\n",
    "posterior = update(prior, likelihood)\n",
    "test_close(np.sum(posterior), 1.0)\n",
    "assert posterior[0] > prior[0]  # First hypothesis should increase\n",
    "\n",
    "# Test sequential updating\n",
    "priors = [0.5, 0.5]\n",
    "likelihoods = [[0.9, 0.1], [0.8, 0.2], [0.7, 0.3]]\n",
    "posteriors = sequential(priors, likelihoods)\n",
    "assert posteriors.shape == (4, 2)  # Initial + 3 updates\n",
    "test_close(np.sum(posteriors, axis=1), 1.0)  # All normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Predictive\n",
    "\n",
    "Sample from the posterior predictive distribution - what future observations might look like given our current beliefs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def predictive(posterior, likelihood_fn, n_samples=1000, rng=None):\n",
    "    \"Sample from posterior predictive distribution\"\n",
    "    if rng is None: rng = np.random.default_rng()\n",
    "    \n",
    "    # Sample parameter values from posterior\n",
    "    param_samples = sample(posterior, n_samples, rng)\n",
    "    \n",
    "    # Generate predictions for each parameter sample\n",
    "    predictions = []\n",
    "    for param_idx in param_samples:\n",
    "        # likelihood_fn should return a distribution over observations\n",
    "        obs_dist = likelihood_fn(param_idx)\n",
    "        obs_sample = sample(obs_dist, 1, rng)\n",
    "        predictions.append(obs_sample)\n",
    "    \n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test posterior predictive\n",
    "posterior = [0.6, 0.4]\n",
    "def simple_likelihood(param_idx):\n",
    "    if param_idx == 0:\n",
    "        return [0.8, 0.2]  # Biased toward observation 0\n",
    "    else:\n",
    "        return [0.3, 0.7]  # Biased toward observation 1\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "predictions = predictive(posterior, simple_likelihood, n_samples=100, rng=rng)\n",
    "assert len(predictions) == 100\n",
    "assert np.all((predictions >= 0) & (predictions <= 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Factors\n",
    "\n",
    "Compare evidence for different hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def bayes_factor(likelihood1, likelihood2, data):\n",
    "    \"Calculate Bayes factor for hypothesis 1 vs 2 given `data`\"\n",
    "    # For single observation\n",
    "    if np.isscalar(data):\n",
    "        return likelihood1[data] / likelihood2[data]\n",
    "    \n",
    "    # For multiple observations (assuming independence)\n",
    "    bf = 1.0\n",
    "    for obs in data:\n",
    "        bf *= likelihood1[obs] / likelihood2[obs]\n",
    "    return bf\n",
    "\n",
    "def interpret_bf(bf):\n",
    "    \"Interpret Bayes factor strength\"\n",
    "    if bf < 1/100:\n",
    "        return \"Decisive evidence against H1\"\n",
    "    elif bf < 1/10:\n",
    "        return \"Strong evidence against H1\"\n",
    "    elif bf < 1/3:\n",
    "        return \"Moderate evidence against H1\"\n",
    "    elif bf < 1:\n",
    "        return \"Weak evidence against H1\"\n",
    "    elif bf < 3:\n",
    "        return \"Weak evidence for H1\"\n",
    "    elif bf < 10:\n",
    "        return \"Moderate evidence for H1\"\n",
    "    elif bf < 100:\n",
    "        return \"Strong evidence for H1\"\n",
    "    else:\n",
    "        return \"Decisive evidence for H1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Bayes factors\n",
    "like1 = [0.9, 0.1]  # H1: mostly generates observation 0\n",
    "like2 = [0.2, 0.8]  # H2: mostly generates observation 1\n",
    "\n",
    "bf_single = bayes_factor(like1, like2, 0)\n",
    "test_close(bf_single, 4.5)  # 0.9/0.2\n",
    "\n",
    "bf_multiple = bayes_factor(like1, like2, [0, 0, 1])\n",
    "test_close(bf_multiple, 4.5 * 4.5 * 0.125)  # (0.9/0.2)^2 * (0.1/0.8)\n",
    "\n",
    "# Test interpretation\n",
    "assert \"Strong evidence for\" in interpret_bf(50)\n",
    "assert \"Weak evidence against\" in interpret_bf(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjugate Priors\n",
    "\n",
    "Helper functions for common conjugate prior-likelihood pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def beta_binomial_update(alpha, beta, successes, failures):\n",
    "    \"Update Beta prior with binomial data\"\n",
    "    return alpha + successes, beta + failures\n",
    "\n",
    "def normal_normal_update(prior_mean, prior_var, data_mean, data_var, n_obs):\n",
    "    \"Update Normal prior with Normal likelihood\"\n",
    "    # Precision weighting\n",
    "    prior_prec = 1 / prior_var\n",
    "    data_prec = n_obs / data_var\n",
    "    \n",
    "    post_prec = prior_prec + data_prec\n",
    "    post_mean = (prior_prec * prior_mean + data_prec * data_mean) / post_prec\n",
    "    post_var = 1 / post_prec\n",
    "    \n",
    "    return post_mean, post_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test conjugate updates\n",
    "# Beta-Binomial\n",
    "alpha_post, beta_post = beta_binomial_update(1, 1, 7, 3)\n",
    "test_eq(alpha_post, 8)\n",
    "test_eq(beta_post, 4)\n",
    "\n",
    "# Normal-Normal  \n",
    "post_mean, post_var = normal_normal_update(0, 1, 2, 0.5, 10)\n",
    "# Should be weighted toward data due to more observations\n",
    "assert 1.5 < post_mean < 2.0\n",
    "assert post_var < 0.5  # Should be more certain than either alone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "__all__ = [\n",
    "    # Core updates\n",
    "    'update', 'sequential',\n",
    "    \n",
    "    # Posterior predictive\n",
    "    'predictive',\n",
    "    \n",
    "    # Model comparison\n",
    "    'bayes_factor', 'interpret_bf',\n",
    "    \n",
    "    # Conjugate priors\n",
    "    'beta_binomial_update', 'normal_normal_update'\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
