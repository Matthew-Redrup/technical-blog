{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Core\n",
    "\n",
    "> Core Bayesian inference functions - updates, sequential processing, and posterior predictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp rbe.bayes_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "from typing import Optional, Union, List, Callable\n",
    "from fastcore.test import test_eq, test_close\n",
    "from fastcore.all import *\n",
    "from technical_blog.rbe.probability import normalize, sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Bayesian Updates\n",
    "\n",
    "The heart of Bayesian inference - updating beliefs with evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `update()` function is the core implementation of **Bayes' theorem** - it's how we mathematically update our beliefs when we receive new evidence. Let me break it down:\n",
    "\n",
    "### What Bayes' Theorem Does\n",
    "\n",
    "Bayes' theorem tells us how to revise our beliefs (prior) when we observe new evidence:\n",
    "\n",
    "$$P(H|E) = \\frac{P(E|H) \\times P(H)}{P(E)}$$\n",
    "\n",
    "Where:\n",
    "- **P(H|E)** = posterior (updated belief after seeing evidence)\n",
    "- **P(E|H)** = likelihood (how probable the evidence is under each hypothesis)\n",
    "- **P(H)** = prior (our initial belief before seeing evidence)\n",
    "- **P(E)** = evidence (total probability of observing this evidence)\n",
    "\n",
    "## How the Function Works\n",
    "\n",
    "```python\n",
    "def update(prior, likelihood, evidence=None):\n",
    "    # Returns: (prior * likelihood) / evidence\n",
    "```\n",
    "\n",
    "**Step 1: Input Validation**\n",
    "- Ensures prior and likelihood have the same shape\n",
    "- Checks for non-negative values (probabilities can't be negative)\n",
    "- Auto-normalizes the prior if it doesn't sum to 1\n",
    "\n",
    "**Step 2: Calculate Evidence**\n",
    "If not provided, evidence is computed as: `evidence = sum(prior * likelihood)`\n",
    "\n",
    "This represents the total probability of seeing the evidence across all possible hypotheses.\n",
    "\n",
    "**Step 3: Apply Bayes' Rule**\n",
    "Returns `(prior * likelihood) / evidence`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def update(prior, # Prior probabilities\n",
    "           likelihood, # Likelihood of evidence given hypothesis\n",
    "           evidence=None # Optional evidence, defaults to sum(prior * likelihood)\n",
    "           ):\n",
    "    \"\"\"Update prior beliefs with likelihood using Bayes' theorem.\"\"\"\n",
    "    prior = np.asarray(prior, dtype=np.float64)\n",
    "    likelihood = np.asarray(likelihood, dtype=np.float64)\n",
    "    \n",
    "    # Validate inputs\n",
    "    if prior.shape != likelihood.shape: raise ValueError(f\"Prior and likelihood shapes don't match: {prior.shape} vs {likelihood.shape}\")\n",
    "    if np.any(prior < 0) or np.any(likelihood < 0): raise ValueError(\"Prior and likelihood must be non-negative\")\n",
    "    # Normalize prior if needed (common in practice)\n",
    "    if not np.isclose(np.sum(prior), 1.0): prior = normalize(prior)\n",
    "    # Compute evidence if not provided\n",
    "    if evidence is None: evidence = np.sum(prior * likelihood)\n",
    "    # Check for impossible observation\n",
    "    if evidence == 0: raise ValueError(\"Impossible observation: zero evidence\")\n",
    "    # Numerical stability check\n",
    "    if evidence < 1e-15:\n",
    "        import warnings\n",
    "        warnings.warn(\"Very small evidence value - numerical instability possible\")\n",
    "    \n",
    "    return (prior * likelihood) / evidence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyber Security Example\n",
    "\n",
    "Imagine you're detecting network intrusions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10714286, 0.66666667, 0.22619048])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prior beliefs about network state\n",
    "prior = [0.9, 0.08, 0.02]  # [normal, suspicious, attack]\n",
    "\n",
    "# New evidence: unusual port scanning detected\n",
    "# Likelihood of seeing port scans under each hypothesis\n",
    "likelihood = [0.01, 0.7, 0.95]  # Very unlikely if normal, likely if attack\n",
    "\n",
    "# Update beliefs\n",
    "posterior = update(prior, likelihood)\n",
    "# Result: attack probability increases significantly!\n",
    "posterior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Key Features for Robust Applications\n",
    "\n",
    "**Automatic Normalization**: Handles unnormalized priors (common when combining multiple sources)\n",
    "\n",
    "**Error Handling**: \n",
    "- Detects impossible observations (zero evidence)\n",
    "- Warns about numerical instability\n",
    "- Validates input shapes and non-negativity\n",
    "\n",
    "**Numerical Stability**: Uses float64 precision to handle the tiny probabilities common in some applications\n",
    "\n",
    "The beauty is that this single function encapsulates the mathematical foundation of all Bayesian learning - whether you're tracking individual threats or updating complex network models, it all comes down to this core update rule!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Bayesian updates\n",
    "prior = np.array([0.3, 0.7])\n",
    "likelihood = np.array([0.8, 0.2])\n",
    "posterior = update(prior, likelihood)\n",
    "test_close(np.sum(posterior), 1.0)\n",
    "assert posterior[0] > prior[0]  # First hypothesis should increase\n",
    "# Test with unnormalized prior (common in practice)\n",
    "unnorm_prior = [3, 7]  # Sums to 10, not 1\n",
    "likelihood = [0.8, 0.2]\n",
    "posterior = update(unnorm_prior, likelihood)\n",
    "test_close(np.sum(posterior), 1.0)\n",
    "\n",
    "# Test numerical stability with tiny values\n",
    "tiny_prior = [1e-10, 1-1e-10]\n",
    "tiny_likelihood = [1e-10, 1-1e-10]\n",
    "posterior = update(tiny_prior, tiny_likelihood)\n",
    "test_close(np.sum(posterior), 1.0)\n",
    "\n",
    "# Test shape mismatch error\n",
    "try:\n",
    "    update([0.5, 0.5], [0.8, 0.2, 0.1])\n",
    "    assert False, \"Should raise ValueError for shape mismatch\"\n",
    "except ValueError as e:\n",
    "    assert \"shapes don't match\" in str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sequential(priors, likelihoods, evidences=None):\n",
    "    \"Sequential updating of `priors` with `likelihoods`\"\n",
    "    if evidences is None:\n",
    "        evidences = [None] * len(likelihoods)\n",
    "    \n",
    "    posterior = np.array(priors)\n",
    "    posteriors = [posterior.copy()]\n",
    "    \n",
    "    for likelihood, evidence in zip(likelihoods, evidences):\n",
    "        posterior = update(posterior, likelihood, evidence)\n",
    "        posteriors.append(posterior.copy())\n",
    "    \n",
    "    return np.array(posteriors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sequential updating\n",
    "priors = [0.5, 0.5]\n",
    "likelihoods = [[0.9, 0.1], [0.8, 0.2], [0.7, 0.3]]\n",
    "posteriors = sequential(priors, likelihoods)\n",
    "assert posteriors.shape == (4, 2)  # Initial + 3 updates\n",
    "test_close(np.sum(posteriors, axis=1), 1.0)  # All normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Predictive\n",
    "\n",
    "Sample from the posterior predictive distribution - what future observations might look like given our current beliefs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def predictive(posterior, likelihood_fn, n_samples=1000, rng=None):\n",
    "    \"Sample from posterior predictive distribution\"\n",
    "    if rng is None: rng = np.random.default_rng()\n",
    "    \n",
    "    # Sample parameter values from posterior\n",
    "    param_samples = sample(posterior, n_samples, rng)\n",
    "    \n",
    "    # Generate predictions for each parameter sample\n",
    "    predictions = []\n",
    "    for param_idx in param_samples:\n",
    "        # likelihood_fn should return a distribution over observations\n",
    "        obs_dist = likelihood_fn(param_idx)\n",
    "        obs_sample = sample(obs_dist, 1, rng)\n",
    "        predictions.append(obs_sample)\n",
    "    \n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test posterior predictive\n",
    "posterior = [0.6, 0.4]\n",
    "def simple_likelihood(param_idx):\n",
    "    if param_idx == 0:\n",
    "        return [0.8, 0.2]  # Biased toward observation 0\n",
    "    else:\n",
    "        return [0.3, 0.7]  # Biased toward observation 1\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "predictions = predictive(posterior, simple_likelihood, n_samples=100, rng=rng)\n",
    "assert len(predictions) == 100\n",
    "assert np.all((predictions >= 0) & (predictions <= 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Factors\n",
    "\n",
    "Compare evidence for different hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def bayes_factor(likelihood1, likelihood2, data):\n",
    "    \"Calculate Bayes factor for hypothesis 1 vs 2 given `data`\"\n",
    "    # For single observation\n",
    "    if np.isscalar(data):\n",
    "        return likelihood1[data] / likelihood2[data]\n",
    "    \n",
    "    # For multiple observations (assuming independence)\n",
    "    bf = 1.0\n",
    "    for obs in data:\n",
    "        bf *= likelihood1[obs] / likelihood2[obs]\n",
    "    return bf\n",
    "\n",
    "def interpret_bf(bf):\n",
    "    \"Interpret Bayes factor strength\"\n",
    "    if bf < 1/100:\n",
    "        return \"Decisive evidence against H1\"\n",
    "    elif bf < 1/10:\n",
    "        return \"Strong evidence against H1\"\n",
    "    elif bf < 1/3:\n",
    "        return \"Moderate evidence against H1\"\n",
    "    elif bf < 1:\n",
    "        return \"Weak evidence against H1\"\n",
    "    elif bf < 3:\n",
    "        return \"Weak evidence for H1\"\n",
    "    elif bf < 10:\n",
    "        return \"Moderate evidence for H1\"\n",
    "    elif bf < 100:\n",
    "        return \"Strong evidence for H1\"\n",
    "    else:\n",
    "        return \"Decisive evidence for H1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Bayes factors\n",
    "like1 = [0.9, 0.1]  # H1: mostly generates observation 0\n",
    "like2 = [0.2, 0.8]  # H2: mostly generates observation 1\n",
    "\n",
    "bf_single = bayes_factor(like1, like2, 0)\n",
    "test_close(bf_single, 4.5)  # 0.9/0.2\n",
    "\n",
    "bf_multiple = bayes_factor(like1, like2, [0, 0, 1])\n",
    "test_close(bf_multiple, 4.5 * 4.5 * 0.125)  # (0.9/0.2)^2 * (0.1/0.8)\n",
    "\n",
    "# Test interpretation\n",
    "assert \"Strong evidence for\" in interpret_bf(50)\n",
    "assert \"Weak evidence against\" in interpret_bf(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjugate Priors\n",
    "\n",
    "Helper functions for common conjugate prior-likelihood pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def beta_binomial_update(alpha, beta, successes, failures):\n",
    "    \"Update Beta prior with binomial data\"\n",
    "    return alpha + successes, beta + failures\n",
    "\n",
    "def normal_normal_update(prior_mean, prior_var, data_mean, data_var, n_obs):\n",
    "    \"Update Normal prior with Normal likelihood\"\n",
    "    # Precision weighting\n",
    "    prior_prec = 1 / prior_var\n",
    "    data_prec = n_obs / data_var\n",
    "    \n",
    "    post_prec = prior_prec + data_prec\n",
    "    post_mean = (prior_prec * prior_mean + data_prec * data_mean) / post_prec\n",
    "    post_var = 1 / post_prec\n",
    "    \n",
    "    return post_mean, post_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test conjugate updates\n",
    "# Beta-Binomial\n",
    "alpha_post, beta_post = beta_binomial_update(1, 1, 7, 3)\n",
    "test_eq(alpha_post, 8)\n",
    "test_eq(beta_post, 4)\n",
    "\n",
    "# Normal-Normal  \n",
    "post_mean, post_var = normal_normal_update(0, 1, 2, 0.5, 10)\n",
    "# Should be weighted toward data due to more observations\n",
    "assert 1.5 < post_mean < 2.0\n",
    "assert post_var < 0.5  # Should be more certain than either alone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "__all__ = [\n",
    "    # Core updates\n",
    "    'update', 'sequential',\n",
    "    \n",
    "    # Posterior predictive\n",
    "    'predictive',\n",
    "    \n",
    "    # Model comparison\n",
    "    'bayes_factor', 'interpret_bf',\n",
    "    \n",
    "    # Conjugate priors\n",
    "    'beta_binomial_update', 'normal_normal_update'\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
