{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Core\n",
    "\n",
    "> Core Bayesian inference functions - updates, sequential processing, and posterior predictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp rbe.bayes_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "from typing import Optional, Union, List, Callable\n",
    "from fastcore.test import test_eq, test_close\n",
    "from fastcore.all import *\n",
    "from technical_blog.rbe.probability import normalize, sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Bayesian Updates\n",
    "\n",
    "The heart of Bayesian inference - updating beliefs with evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `update()` function is the core implementation of **Bayes' theorem** - it's how we mathematically update our beliefs when we receive new evidence. Let me break it down:\n",
    "\n",
    "### What Bayes' Theorem Does\n",
    "\n",
    "Bayes' theorem tells us how to revise our beliefs (prior) when we observe new evidence:\n",
    "\n",
    "$$P(H|E) = \\frac{P(E|H) \\times P(H)}{P(E)}$$\n",
    "\n",
    "Where:\n",
    "- **P(H|E)** = posterior (updated belief after seeing evidence)\n",
    "- **P(E|H)** = likelihood (how probable the evidence is under each hypothesis)\n",
    "- **P(H)** = prior (our initial belief before seeing evidence)\n",
    "- **P(E)** = evidence (total probability of observing this evidence)\n",
    "\n",
    "## How the Function Works\n",
    "\n",
    "```python\n",
    "def update(prior, likelihood, evidence=None):\n",
    "    # Returns: (prior * likelihood) / evidence\n",
    "```\n",
    "\n",
    "**Step 1: Input Validation**\n",
    "- Ensures prior and likelihood have the same shape\n",
    "- Checks for non-negative values (probabilities can't be negative)\n",
    "- Auto-normalizes the prior if it doesn't sum to 1\n",
    "\n",
    "**Step 2: Calculate Evidence**\n",
    "If not provided, evidence is computed as: `evidence = sum(prior * likelihood)`\n",
    "\n",
    "This represents the total probability of seeing the evidence across all possible hypotheses.\n",
    "\n",
    "**Step 3: Apply Bayes' Rule**\n",
    "Returns `(prior * likelihood) / evidence`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def update(prior, # Prior probabilities\n",
    "           likelihood, # Likelihood of evidence given hypothesis\n",
    "           evidence=None # Optional evidence, defaults to sum(prior * likelihood)\n",
    "           ):\n",
    "    \"\"\"Update prior beliefs with likelihood using Bayes' theorem.\"\"\"\n",
    "    prior = np.asarray(prior, dtype=np.float64)\n",
    "    likelihood = np.asarray(likelihood, dtype=np.float64)\n",
    "    \n",
    "    # Validate inputs\n",
    "    if prior.shape != likelihood.shape: raise ValueError(f\"Prior and likelihood shapes don't match: {prior.shape} vs {likelihood.shape}\")\n",
    "    if np.any(prior < 0) or np.any(likelihood < 0): raise ValueError(\"Prior and likelihood must be non-negative\")\n",
    "    # Normalize prior if needed (common in practice)\n",
    "    if not np.isclose(np.sum(prior), 1.0): prior = normalize(prior)\n",
    "    # Compute evidence if not provided\n",
    "    if evidence is None: evidence = np.sum(prior * likelihood)\n",
    "    # Check for impossible observation\n",
    "    if evidence == 0: raise ValueError(\"Impossible observation: zero evidence\")\n",
    "    # Numerical stability check\n",
    "    if evidence < 1e-15:\n",
    "        import warnings\n",
    "        warnings.warn(\"Very small evidence value - numerical instability possible\")\n",
    "    \n",
    "    return (prior * likelihood) / evidence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyber Security Example\n",
    "\n",
    "Imagine you're detecting network intrusions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10714286, 0.66666667, 0.22619048])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prior beliefs about network state\n",
    "prior = [0.9, 0.08, 0.02]  # [normal, suspicious, attack]\n",
    "\n",
    "# New evidence: unusual port scanning detected\n",
    "# Likelihood of seeing port scans under each hypothesis\n",
    "likelihood = [0.01, 0.7, 0.95]  # Very unlikely if normal, likely if attack\n",
    "\n",
    "# Update beliefs\n",
    "posterior = update(prior, likelihood)\n",
    "# Result: attack probability increases significantly!\n",
    "posterior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Key Features for Robust Applications\n",
    "\n",
    "**Automatic Normalization**: Handles unnormalized priors (common when combining multiple sources)\n",
    "\n",
    "**Error Handling**: \n",
    "- Detects impossible observations (zero evidence)\n",
    "- Warns about numerical instability\n",
    "- Validates input shapes and non-negativity\n",
    "\n",
    "**Numerical Stability**: Uses float64 precision to handle the tiny probabilities common in some applications\n",
    "\n",
    "The beauty is that this single function encapsulates the mathematical foundation of all Bayesian learning - whether you're tracking individual threats or updating complex network models, it all comes down to this core update rule!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Bayesian updates\n",
    "prior = np.array([0.3, 0.7])\n",
    "likelihood = np.array([0.8, 0.2])\n",
    "posterior = update(prior, likelihood)\n",
    "test_close(np.sum(posterior), 1.0)\n",
    "assert posterior[0] > prior[0]  # First hypothesis should increase\n",
    "# Test with unnormalized prior (common in practice)\n",
    "unnorm_prior = [3, 7]  # Sums to 10, not 1\n",
    "likelihood = [0.8, 0.2]\n",
    "posterior = update(unnorm_prior, likelihood)\n",
    "test_close(np.sum(posterior), 1.0)\n",
    "\n",
    "# Test numerical stability with tiny values\n",
    "tiny_prior = [1e-10, 1-1e-10]\n",
    "tiny_likelihood = [1e-10, 1-1e-10]\n",
    "posterior = update(tiny_prior, tiny_likelihood)\n",
    "test_close(np.sum(posterior), 1.0)\n",
    "\n",
    "# Test shape mismatch error\n",
    "try:\n",
    "    update([0.5, 0.5], [0.8, 0.2, 0.1])\n",
    "    assert False, \"Should raise ValueError for shape mismatch\"\n",
    "except ValueError as e:\n",
    "    assert \"shapes don't match\" in str(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential\n",
    "The `sequential` function implements **sequential Bayesian updating** - it's how you process multiple observations one after another, updating your beliefs with each new piece of evidence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sequential(priors,  # prior probabilities of hypotheses \n",
    "               likelihoods, # likelihoods of observations given hypotheses\n",
    "               evidences=None # evidence for each observation\n",
    "               ):\n",
    "    \"\"\"Sequential Bayesian updates with multiple observations.\"\"\"\n",
    "    priors = np.asarray(priors, dtype=np.float64)\n",
    "    likelihoods = np.asarray(likelihoods, dtype=np.float64)\n",
    "    \n",
    "    # Validate inputs\n",
    "    if len(likelihoods) == 0:\n",
    "        return np.array([priors])\n",
    "    \n",
    "    if likelihoods.ndim != 2:\n",
    "        raise ValueError(\"Likelihoods must be 2D array (n_observations, n_hypotheses)\")\n",
    "    \n",
    "    if likelihoods.shape[1] != len(priors):\n",
    "        raise ValueError(f\"Likelihood shape {likelihoods.shape} incompatible with prior length {len(priors)}\")\n",
    "    \n",
    "    if evidences is None:\n",
    "        evidences = [None] * len(likelihoods)\n",
    "    elif len(evidences) != len(likelihoods):\n",
    "        raise ValueError(\"Number of evidences must match number of likelihoods\")\n",
    "    \n",
    "    # Perform sequential updates\n",
    "    posterior = priors.copy()\n",
    "    posteriors = [posterior.copy()]\n",
    "    \n",
    "    for likelihood, evidence in zip(likelihoods, evidences):\n",
    "        posterior = update(posterior, likelihood, evidence)\n",
    "        posteriors.append(posterior.copy())\n",
    "    \n",
    "    return np.array(posteriors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What It Does\n",
    "\n",
    "Instead of updating beliefs with just one observation (like the basic `update` function), `sequential` handles a whole series of observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95      , 0.04      , 0.01      ],\n",
       "       [0.7421875 , 0.1875    , 0.0703125 ],\n",
       "       [0.14615385, 0.59076923, 0.26307692],\n",
       "       [0.07483261, 0.45372194, 0.47144545],\n",
       "       [0.49414824, 0.33289987, 0.17295189]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with initial beliefs\n",
    "prior = [0.95, 0.04, 0.01]  # [normal, suspicious, attack]\n",
    "\n",
    "# Process multiple observations over time\n",
    "observations = [\n",
    "    [0.1, 0.6, 0.9],   # High anomaly score\n",
    "    [0.05, 0.8, 0.95], # Even higher anomaly  \n",
    "    [0.2, 0.3, 0.7],   # Moderate anomaly\n",
    "    [0.9, 0.1, 0.05]   # Back to normal\n",
    "]\n",
    "\n",
    "timeline = sequential(prior, observations)\n",
    "# Returns: array of beliefs after each observation\n",
    "timeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### How It Works\n",
    "\n",
    "The function performs these steps:\n",
    "\n",
    "1. **Starts with your prior beliefs**\n",
    "2. **For each observation**:\n",
    "   - Takes current beliefs as the \"prior\" for this update\n",
    "   - Applies Bayes' theorem using the observation's likelihood\n",
    "   - The resulting posterior becomes the prior for the next observation\n",
    "3. **Returns the complete timeline** of how beliefs evolved\n",
    "\n",
    "Mathematically, it's chaining Bayes' updates:\n",
    "- After obs 1: `P(H|obs1) = P(obs1|H) × P(H) / P(obs1)`\n",
    "- After obs 2: `P(H|obs1,obs2) = P(obs2|H) × P(H|obs1) / P(obs2)`\n",
    "- And so on...\n",
    "\n",
    "#### Key Features for Cyber Security\n",
    "\n",
    "**Timeline Tracking**: You get the complete evolution of beliefs, not just the final result. This lets you see:\n",
    "- When threat probability peaked\n",
    "- How quickly beliefs changed\n",
    "- Whether the system is converging or oscillating\n",
    "\n",
    "**Robust Error Handling**: \n",
    "- Validates that likelihoods are properly shaped (2D array)\n",
    "- Ensures evidence counts match observations\n",
    "- Handles edge cases like empty observation sequences\n",
    "\n",
    "**Memory Efficiency**: Processes observations one at a time rather than requiring all data in memory simultaneously.\n",
    "\n",
    "#### Cyber Security Example\n",
    "\n",
    "In a network anomaly detection scenario:\n",
    "\n",
    "```python\n",
    "# Each row represents likelihood of observation under each network state\n",
    "# [normal_likelihood, suspicious_likelihood, attack_likelihood]\n",
    "network_observations = [\n",
    "    [0.1, 0.6, 0.9],   # Suspicious traffic pattern\n",
    "    [0.05, 0.8, 0.95], # Even more suspicious\n",
    "    [0.9, 0.1, 0.05]   # Returns to normal\n",
    "]\n",
    "\n",
    "belief_timeline = sequential(network_prior, network_observations)\n",
    "```\n",
    "\n",
    "This gives you a complete picture of how your RBE's confidence in different threat levels evolved as new network data arrived - essential for understanding both the current threat state and the system's decision-making process.\n",
    "\n",
    "The function essentially turns your single-shot Bayesian update into a learning system that accumulates evidence over time!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Edge Cases & Error Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sequential updating\n",
    "priors = [0.5, 0.5]\n",
    "likelihoods = [[0.9, 0.1], [0.8, 0.2], [0.7, 0.3]]\n",
    "posteriors = sequential(priors, likelihoods)\n",
    "assert posteriors.shape == (4, 2)  # Initial + 3 updates\n",
    "test_close(np.sum(posteriors, axis=1), 1.0)  # All normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty observations (should return just the prior)\n",
    "empty_result = sequential([0.6, 0.4], [])\n",
    "test_eq(empty_result.shape, (1, 2))\n",
    "test_close(empty_result[0], [0.6, 0.4])\n",
    "\n",
    "# Single observation (common case)\n",
    "single_result = sequential([0.5, 0.5], [[0.8, 0.2]])\n",
    "test_eq(single_result.shape, (2, 2))\n",
    "\n",
    "# Test with custom evidences\n",
    "priors = [0.4, 0.6]\n",
    "likelihoods = [[0.9, 0.1], [0.7, 0.3]]\n",
    "evidences = [0.5, 0.8]  # Custom evidence values\n",
    "result = sequential(priors, likelihoods, evidences)\n",
    "# Should use provided evidences instead of computing them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Cyber Security Specific Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realistic network anomaly scenario\n",
    "network_prior = [0.95, 0.04, 0.01]  # [normal, suspicious, attack]\n",
    "\n",
    "# Sequence of observations over time\n",
    "observations = [\n",
    "    [0.1, 0.6, 0.9],   # High anomaly score\n",
    "    [0.05, 0.8, 0.95], # Even higher anomaly\n",
    "    [0.2, 0.3, 0.7],   # Moderate anomaly\n",
    "    [0.9, 0.1, 0.05]   # Back to normal\n",
    "]\n",
    "\n",
    "timeline = sequential(network_prior, observations)\n",
    "\n",
    "# Verify attack probability peaks and then decreases\n",
    "attack_probs = timeline[:, 2]  # Extract attack column\n",
    "peak_idx = np.argmax(attack_probs[1:]) + 1  # Skip initial prior\n",
    "assert attack_probs[peak_idx] > attack_probs[0], \"Attack probability should increase\"\n",
    "assert attack_probs[-1] < attack_probs[peak_idx], \"Should decrease after normal observation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numerical Stability Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very small likelihoods (rare events)\n",
    "tiny_likelihoods = [[1e-15, 1-1e-15], [1e-14, 1-1e-14]]\n",
    "result = sequential([0.5, 0.5], tiny_likelihoods)\n",
    "assert np.all(np.isfinite(result)), \"Should handle tiny values\"\n",
    "\n",
    "# Extreme confidence updates\n",
    "extreme_likes = [[0.999, 0.001], [0.001, 0.999]]\n",
    "result = sequential([0.5, 0.5], extreme_likes)\n",
    "# Should handle rapid belief changes without numerical issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Input Validation Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrong likelihood dimensions\n",
    "try:\n",
    "    sequential([0.5, 0.5], [0.8, 0.2])  # 1D instead of 2D\n",
    "    assert False, \"Should reject 1D likelihoods\"\n",
    "except ValueError as e:\n",
    "    assert \"2D array\" in str(e)\n",
    "\n",
    "# Mismatched evidence count\n",
    "try:\n",
    "    sequential([0.5, 0.5], [[0.8, 0.2]], evidences=[0.5, 0.6])  # 2 evidences, 1 likelihood\n",
    "    assert False, \"Should reject mismatched evidence count\"\n",
    "except ValueError as e:\n",
    "    assert \"match number of likelihoods\" in str(e)\n",
    "\n",
    "# Incompatible shapes\n",
    "try:\n",
    "    sequential([0.5, 0.5], [[0.8, 0.2, 0.1]])  # 3 hypotheses vs 2 in prior\n",
    "    assert False, \"Should reject shape mismatch\"\n",
    "except ValueError as e:\n",
    "    assert \"incompatible\" in str(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convergence and Learning Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test convergence with consistent evidence\n",
    "consistent_evidence = [[0.9, 0.1]] * 10  # Same observation repeated\n",
    "result = sequential([0.5, 0.5], consistent_evidence)\n",
    "\n",
    "# Should converge toward first hypothesis\n",
    "final_belief = result[-1, 0]\n",
    "assert final_belief > 0.95, \"Should strongly favor consistent hypothesis\"\n",
    "\n",
    "# Test belief oscillation with conflicting evidence\n",
    "conflicting = [[0.9, 0.1], [0.1, 0.9]] * 5  # Alternating evidence\n",
    "result = sequential([0.5, 0.5], conflicting)\n",
    "# Final belief shouldn't be too extreme in either direction\n",
    "assert 0.2 < result[-1, 0] < 0.8, \"Conflicting evidence should maintain uncertainty\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Predictive\n",
    "\n",
    "Sample from the posterior predictive distribution - what future observations might look like given our current beliefs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `predictive` function implements **posterior predictive sampling** - a key technique in Bayesian inference that answers the question: \"Given what I've learned so far, what kinds of observations might I see in the future?\"\n",
    "\n",
    "#### What It Does\n",
    "\n",
    "The function generates synthetic future observations by combining:\n",
    "1. **Your current beliefs** (posterior distribution over parameters/hypotheses)\n",
    "2. **The observation model** (likelihood function that maps parameters to observation probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def predictive(posterior, likelihood_fn, n_samples=1000, rng=None):\n",
    "    \"\"\"Vectorized posterior predictive sampling.\"\"\"\n",
    "    if rng is None: rng = np.random.default_rng()\n",
    "    \n",
    "    posterior = normalize(posterior)\n",
    "    param_samples = sample(posterior, n_samples, rng)\n",
    "    \n",
    "    # Group samples by parameter for efficient batch processing\n",
    "    unique_params, counts = np.unique(param_samples, return_counts=True)\n",
    "    \n",
    "    predictions = []\n",
    "    for param_idx, count in zip(unique_params, counts):\n",
    "        obs_dist = normalize(likelihood_fn(param_idx))\n",
    "        obs_samples = sample(obs_dist, count, rng)\n",
    "        predictions.extend(obs_samples)\n",
    "    \n",
    "    # Shuffle to remove parameter ordering bias\n",
    "    rng.shuffle(predictions)\n",
    "    return np.array(predictions, dtype=int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### How It Works\n",
    "\n",
    "The algorithm follows a two-step process that mirrors the generative story of Bayesian models:\n",
    "\n",
    "**Step 1: Sample Parameters**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "param_samples = sample(posterior, n_samples, rng)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This draws parameter values according to your current beliefs. If you're 70% confident in \"normal network state\" and 30% confident in \"attack state\", about 70% of the samples will be \"normal\".\n",
    "\n",
    "**Step 2: Generate Observations**\n",
    "For each sampled parameter, use the likelihood function to determine what observations that parameter would generate:\n",
    "```python\n",
    "obs_dist = normalize(likelihood_fn(param_idx))\n",
    "obs_samples = sample(obs_dist, count, rng)\n",
    "```\n",
    "\n",
    "## Clever Optimization\n",
    "\n",
    "The function uses **vectorized batch processing** for efficiency:\n",
    "\n",
    "```python\n",
    "unique_params, counts = np.unique(param_samples, return_counts=True)\n",
    "```\n",
    "\n",
    "Instead of processing 1000 individual samples, it groups them: \"I need 700 observations from parameter 0 and 300 from parameter 1.\" This is much faster than generating observations one by one.\n",
    "\n",
    "## Cyber Security Applications\n",
    "\n",
    "**1. Threat Forecasting**\n",
    "```python\n",
    "# Current beliefs about network state\n",
    "network_posterior = [0.6, 0.3, 0.1]  # [normal, suspicious, attack]\n",
    "\n",
    "def network_observations(state_idx):\n",
    "    if state_idx == 0:  # Normal state\n",
    "        return [0.9, 0.08, 0.02]  # [normal_traffic, anomaly, alert]\n",
    "    elif state_idx == 1:  # Suspicious state  \n",
    "        return [0.4, 0.5, 0.1]\n",
    "    else:  # Attack state\n",
    "        return [0.1, 0.3, 0.6]\n",
    "\n",
    "# What kinds of network events should we expect?\n",
    "future_events = predictive(network_posterior, network_observations, n_samples=1000)\n",
    "```\n",
    "\n",
    "**2. Anomaly Detection Validation**\n",
    "Generate synthetic data that matches your current model, then compare with actual observations to detect model drift or new attack patterns.\n",
    "\n",
    "**3. Alert System Tuning**\n",
    "Predict how many alerts different threshold settings would generate under your current threat model.\n",
    "\n",
    "**4. Resource Planning**\n",
    "Estimate future computational or analyst workload based on predicted event distributions.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "**Numerical Stability**: Normalizes both posterior and likelihood distributions to ensure valid probabilities.\n",
    "\n",
    "**Reproducibility**: Uses controlled random number generation for consistent results across runs.\n",
    "\n",
    "**Bias Removal**: Shuffles final predictions to remove any ordering artifacts from the batch processing.\n",
    "\n",
    "**Type Safety**: Returns integer indices (not floats) since observations are typically categorical.\n",
    "\n",
    "## Example Output Interpretation\n",
    "\n",
    "If you get predictions like `[0, 0, 1, 0, 0, 2, 0, ...]`, this means:\n",
    "- Most future observations will be type 0 (normal)\n",
    "- Occasional type 1 observations (suspicious)  \n",
    "- Rare type 2 observations (attacks)\n",
    "\n",
    "The relative frequencies tell you what to expect: if 80% are type 0, your model predicts the network will be normal 80% of the time.\n",
    "\n",
    "This is invaluable for **proactive security planning** - instead of just reacting to threats, you can anticipate what's likely to happen and prepare accordingly!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test posterior predictive\n",
    "posterior = [0.6, 0.4]\n",
    "def simple_likelihood(param_idx):\n",
    "    if param_idx == 0:\n",
    "        return [0.8, 0.2]  # Biased toward observation 0\n",
    "    else:\n",
    "        return [0.3, 0.7]  # Biased toward observation 1\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "predictions = predictive(posterior, simple_likelihood, n_samples=100, rng=rng)\n",
    "assert len(predictions) == 100\n",
    "assert np.all((predictions >= 0) & (predictions <= 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = [0.7, 0.3]\n",
    "\n",
    "def likelihood_fn(param_idx):\n",
    "    if param_idx == 0:\n",
    "        return [0.9, 0.1]  # Parameter 0 strongly predicts observation 0\n",
    "    else:\n",
    "        return [0.2, 0.8]  # Parameter 1 strongly predicts observation 1\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "predictions = predictive(posterior, likelihood_fn, n_samples=1000, rng=rng)\n",
    "\n",
    "# Check output format\n",
    "assert predictions.shape == (1000,), \"Should return 1D array\"\n",
    "assert predictions.dtype == int, \"Should return integer indices\"\n",
    "assert np.all((predictions >= 0) & (predictions <= 1)), \"All predictions should be valid indices\"\n",
    "\n",
    "# Check statistical properties\n",
    "# Since posterior favors param 0 (0.7 vs 0.3), and param 0 favors obs 0 (0.9 vs 0.1),\n",
    "# we should see more 0s than 1s in predictions\n",
    "obs_0_count = np.sum(predictions == 0)\n",
    "obs_1_count = np.sum(predictions == 1)\n",
    "assert obs_0_count > obs_1_count, \"Should predict observation 0 more often\"\n",
    "\n",
    "# Rough check: expect about 70% * 90% + 30% * 20% = 69% observation 0\n",
    "expected_ratio = 0.7 * 0.9 + 0.3 * 0.2  # ≈ 0.69\n",
    "actual_ratio = obs_0_count / 1000\n",
    "assert abs(actual_ratio - expected_ratio) < 0.05, f\"Expected ~{expected_ratio:.2f}, got {actual_ratio:.2f}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Factors\n",
    "\n",
    "Compare evidence for different hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def bayes_factor(likelihood1, likelihood2, data):\n",
    "    \"Calculate Bayes factor for hypothesis 1 vs 2 given `data`\"\n",
    "    # For single observation\n",
    "    if np.isscalar(data):\n",
    "        return likelihood1[data] / likelihood2[data]\n",
    "    \n",
    "    # For multiple observations (assuming independence)\n",
    "    bf = 1.0\n",
    "    for obs in data:\n",
    "        bf *= likelihood1[obs] / likelihood2[obs]\n",
    "    return bf\n",
    "\n",
    "def interpret_bf(bf):\n",
    "    \"Interpret Bayes factor strength\"\n",
    "    if bf < 1/100:\n",
    "        return \"Decisive evidence against H1\"\n",
    "    elif bf < 1/10:\n",
    "        return \"Strong evidence against H1\"\n",
    "    elif bf < 1/3:\n",
    "        return \"Moderate evidence against H1\"\n",
    "    elif bf < 1:\n",
    "        return \"Weak evidence against H1\"\n",
    "    elif bf < 3:\n",
    "        return \"Weak evidence for H1\"\n",
    "    elif bf < 10:\n",
    "        return \"Moderate evidence for H1\"\n",
    "    elif bf < 100:\n",
    "        return \"Strong evidence for H1\"\n",
    "    else:\n",
    "        return \"Decisive evidence for H1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Bayes factors\n",
    "like1 = [0.9, 0.1]  # H1: mostly generates observation 0\n",
    "like2 = [0.2, 0.8]  # H2: mostly generates observation 1\n",
    "\n",
    "bf_single = bayes_factor(like1, like2, 0)\n",
    "test_close(bf_single, 4.5)  # 0.9/0.2\n",
    "\n",
    "bf_multiple = bayes_factor(like1, like2, [0, 0, 1])\n",
    "test_close(bf_multiple, 4.5 * 4.5 * 0.125)  # (0.9/0.2)^2 * (0.1/0.8)\n",
    "\n",
    "# Test interpretation\n",
    "assert \"Strong evidence for\" in interpret_bf(50)\n",
    "assert \"Weak evidence against\" in interpret_bf(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjugate Priors\n",
    "\n",
    "Helper functions for common conjugate prior-likelihood pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def beta_binomial_update(alpha, beta, successes, failures):\n",
    "    \"Update Beta prior with binomial data\"\n",
    "    return alpha + successes, beta + failures\n",
    "\n",
    "def normal_normal_update(prior_mean, prior_var, data_mean, data_var, n_obs):\n",
    "    \"Update Normal prior with Normal likelihood\"\n",
    "    # Precision weighting\n",
    "    prior_prec = 1 / prior_var\n",
    "    data_prec = n_obs / data_var\n",
    "    \n",
    "    post_prec = prior_prec + data_prec\n",
    "    post_mean = (prior_prec * prior_mean + data_prec * data_mean) / post_prec\n",
    "    post_var = 1 / post_prec\n",
    "    \n",
    "    return post_mean, post_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test conjugate updates\n",
    "# Beta-Binomial\n",
    "alpha_post, beta_post = beta_binomial_update(1, 1, 7, 3)\n",
    "test_eq(alpha_post, 8)\n",
    "test_eq(beta_post, 4)\n",
    "\n",
    "# Normal-Normal  \n",
    "post_mean, post_var = normal_normal_update(0, 1, 2, 0.5, 10)\n",
    "# Should be weighted toward data due to more observations\n",
    "assert 1.5 < post_mean < 2.0\n",
    "assert post_var < 0.5  # Should be more certain than either alone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "__all__ = [\n",
    "    # Core updates\n",
    "    'update', 'sequential',\n",
    "    \n",
    "    # Posterior predictive\n",
    "    'predictive',\n",
    "    \n",
    "    # Model comparison\n",
    "    'bayes_factor', 'interpret_bf',\n",
    "    \n",
    "    # Conjugate priors\n",
    "    'beta_binomial_update', 'normal_normal_update'\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
