{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cybersecurity Applications\n",
    "\n",
    "> RBE applications for network security, threat detection, and anomaly monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp rbe.cybersecurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "from typing import Dict, List, Optional, Tuple, Callable\n",
    "from fastcore.test import test_eq, test_close\n",
    "from fastcore.all import *\n",
    "from technical_blog.rbe.probability import normalize, entropy\n",
    "from technical_blog.rbe.bayes_core import update\n",
    "from technical_blog.rbe.particle_filter import run as pf_run\n",
    "from technical_blog.rbe.estimator import estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threat Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def intrusion_detection(evidence_sequence, prior_attack=0.05, verbose=False):\n",
    "    \"Sequential intrusion detection using Bayesian updating\"\n",
    "    # Evidence types and their likelihoods [P(evidence|attack), P(evidence|normal)]\n",
    "    evidence_map = {\n",
    "        'port_scan': [0.8, 0.1],\n",
    "        'failed_login': [0.7, 0.3],\n",
    "        'data_transfer': [0.6, 0.4],\n",
    "        'normal_traffic': [0.1, 0.9],\n",
    "        'privilege_escalation': [0.95, 0.01],\n",
    "        'suspicious_process': [0.85, 0.05]\n",
    "    }\n",
    "    \n",
    "    belief = np.array([prior_attack, 1 - prior_attack])\n",
    "    history = [belief.copy()]\n",
    "    \n",
    "    for i, evidence in enumerate(evidence_sequence):\n",
    "        if evidence in evidence_map:\n",
    "            likelihood = np.array(evidence_map[evidence])\n",
    "        else:\n",
    "            likelihood = np.array([0.5, 0.5])  # Unknown evidence\n",
    "        \n",
    "        belief = update(belief, likelihood)\n",
    "        history.append(belief.copy())\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Step {i+1}: {evidence} -> P(attack)={belief[0]:.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'final_belief': belief,\n",
    "        'history': np.array(history),\n",
    "        'attack_probability': belief[0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test intrusion detection\n",
    "evidence = ['normal_traffic', 'port_scan', 'failed_login', 'privilege_escalation']\n",
    "result = intrusion_detection(evidence, verbose=True)\n",
    "assert result['attack_probability'] > 0.9  # Should be very confident about attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Stage Attack Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def multi_stage_detector(event_sequence, attack_patterns, threshold=0.7):\n",
    "    \"Detect multi-stage attack patterns\"\n",
    "    # Initialize beliefs for each pattern\n",
    "    pattern_beliefs = {}\n",
    "    for pattern_name in attack_patterns:\n",
    "        pattern_beliefs[pattern_name] = np.array([0.8, 0.2])  # [benign, attack]\n",
    "    \n",
    "    results = {\n",
    "        'detections': [],\n",
    "        'pattern_probabilities': {name: [] for name in attack_patterns},\n",
    "        'alerts': []\n",
    "    }\n",
    "    \n",
    "    for t, event in enumerate(event_sequence):\n",
    "        alerts_this_step = []\n",
    "        \n",
    "        for pattern_name, pattern_steps in attack_patterns.items():\n",
    "            if event in pattern_steps:\n",
    "                # Strong evidence for attack\n",
    "                likelihood = np.array([0.1, 0.9])\n",
    "            else:\n",
    "                # Evidence against attack\n",
    "                likelihood = np.array([0.8, 0.2])\n",
    "            \n",
    "            pattern_beliefs[pattern_name] = update(pattern_beliefs[pattern_name], likelihood)\n",
    "            attack_prob = pattern_beliefs[pattern_name][1]\n",
    "            \n",
    "            results['pattern_probabilities'][pattern_name].append(attack_prob)\n",
    "            \n",
    "            if attack_prob > threshold:\n",
    "                alerts_this_step.append(pattern_name)\n",
    "        \n",
    "        if alerts_this_step:\n",
    "            results['alerts'].append((t, alerts_this_step))\n",
    "            results['detections'].extend(alerts_this_step)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multi-stage detection\n",
    "patterns = {\n",
    "    'Reconnaissance': ['port_scan', 'dns_lookup', 'service_enum'],\n",
    "    'Exploitation': ['exploit_attempt', 'payload_delivery', 'code_execution'],\n",
    "    'Persistence': ['registry_modification', 'service_creation', 'scheduled_task']\n",
    "}\n",
    "\n",
    "events = ['port_scan', 'normal', 'dns_lookup', 'exploit_attempt', 'service_enum']\n",
    "result = multi_stage_detector(events, patterns)\n",
    "\n",
    "assert 'Reconnaissance' in result['detections']\n",
    "print(f\"Detected patterns: {set(result['detections'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection with Particle Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def network_anomaly_detector(traffic_data, baseline_mean, baseline_std, \n",
    "                           n_particles=500, anomaly_threshold=3.0):\n",
    "    \"Detect network anomalies using particle filtering\"\n",
    "    \n",
    "    def transition(state, rng):\n",
    "        # State = [traffic_level, anomaly_score]\n",
    "        level, score = state\n",
    "        \n",
    "        # Traffic level evolves with some noise\n",
    "        new_level = level + rng.normal(0, baseline_std * 0.1)\n",
    "        \n",
    "        # Anomaly score decays but can spike\n",
    "        new_score = score * 0.9 + rng.exponential(0.1)\n",
    "        \n",
    "        return np.array([new_level, new_score])\n",
    "    \n",
    "    def likelihood(state, observation):\n",
    "        level, score = state\n",
    "        \n",
    "        # How well does state explain observation?\n",
    "        expected = baseline_mean + score * baseline_std\n",
    "        diff = abs(observation - expected)\n",
    "        \n",
    "        return np.exp(-0.5 * (diff / baseline_std)**2)\n",
    "    \n",
    "    # Initialize around baseline\n",
    "    def init_fn(n, dim, rng):\n",
    "        levels = rng.normal(baseline_mean, baseline_std * 0.5, n)\n",
    "        scores = rng.exponential(0.5, n)\n",
    "        return np.column_stack([levels, scores])\n",
    "    \n",
    "    # Run particle filter\n",
    "    result = pf_run(traffic_data, transition, likelihood, \n",
    "                   n_particles=n_particles, init_fn=init_fn)\n",
    "    \n",
    "    # Extract anomaly scores\n",
    "    anomaly_scores = result['estimates'][:, 1]\n",
    "    anomalies = anomaly_scores > anomaly_threshold\n",
    "    \n",
    "    return {\n",
    "        'anomaly_scores': anomaly_scores,\n",
    "        'anomalies': anomalies,\n",
    "        'anomaly_times': np.where(anomalies)[0],\n",
    "        'pf_result': result\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test anomaly detection\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Generate traffic data with anomalies\n",
    "normal_traffic = rng.normal(100, 10, 50)\n",
    "anomaly_traffic = rng.normal(200, 20, 10)  # Spike\n",
    "traffic = np.concatenate([normal_traffic[:20], anomaly_traffic, normal_traffic[20:]])\n",
    "\n",
    "result = network_anomaly_detector(traffic, baseline_mean=100, baseline_std=10)\n",
    "print(f\"Anomalies detected at times: {result['anomaly_times']}\")\n",
    "assert len(result['anomaly_times']) > 0  # Should detect some anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threat Intelligence Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fuse_threat_intel(sources, reliabilities, prior=None):\n",
    "    \"Fuse multiple threat intelligence sources\"\n",
    "    if prior is None:\n",
    "        prior = np.array([0.1, 0.9])  # [threat, no_threat]\n",
    "    \n",
    "    belief = prior.copy()\n",
    "    fusion_history = [belief.copy()]\n",
    "    \n",
    "    for source, reliability in zip(sources, reliabilities):\n",
    "        # Source report: threat_detected (True/False)\n",
    "        if source['threat_detected']:\n",
    "            # Likelihood depends on source reliability\n",
    "            likelihood = np.array([reliability, 1 - reliability])\n",
    "        else:\n",
    "            likelihood = np.array([1 - reliability, reliability])\n",
    "        \n",
    "        belief = update(belief, likelihood)\n",
    "        fusion_history.append(belief.copy())\n",
    "    \n",
    "    # Calculate confidence\n",
    "    confidence = 1 - entropy(belief)\n",
    "    \n",
    "    return {\n",
    "        'final_assessment': belief,\n",
    "        'threat_probability': belief[0],\n",
    "        'confidence': confidence,\n",
    "        'history': np.array(fusion_history)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test threat intelligence fusion\n",
    "sources = [\n",
    "    {'name': 'Commercial_TI', 'threat_detected': True},\n",
    "    {'name': 'OSINT', 'threat_detected': True},\n",
    "    {'name': 'Internal_SOC', 'threat_detected': False},\n",
    "    {'name': 'Government_Feed', 'threat_detected': True}\n",
    "]\n",
    "reliabilities = [0.85, 0.70, 0.90, 0.95]\n",
    "\n",
    "result = fuse_threat_intel(sources, reliabilities)\n",
    "print(f\"Threat probability: {result['threat_probability']:.3f}\")\n",
    "print(f\"Confidence: {result['confidence']:.3f}\")\n",
    "assert result['threat_probability'] > 0.5  # Should indicate threat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Baseline Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def adaptive_monitor(data, window_size=20, adapt_rate=0.1, \n",
    "                    alert_threshold=2.5, decay_rate=0.05):\n",
    "    \"Monitor with adaptive baseline and threat detection\"\n",
    "    \n",
    "    results = {\n",
    "        'threat_scores': [],\n",
    "        'baselines': [],\n",
    "        'alerts': [],\n",
    "        'threat_belief': []\n",
    "    }\n",
    "    \n",
    "    # Initialize\n",
    "    if len(data) < window_size:\n",
    "        baseline = np.mean(data)\n",
    "        baseline_std = np.std(data) if len(data) > 1 else 1.0\n",
    "    else:\n",
    "        baseline = np.mean(data[:window_size])\n",
    "        baseline_std = np.std(data[:window_size])\n",
    "    \n",
    "    threat_belief = np.array([0.5, 0.5])  # [normal, threat]\n",
    "    \n",
    "    for t, obs in enumerate(data):\n",
    "        # Calculate deviation\n",
    "        z_score = abs(obs - baseline) / (baseline_std + 1e-6)\n",
    "        \n",
    "        # Update threat belief\n",
    "        if z_score < 1.0:\n",
    "            likelihood = np.array([0.9, 0.1])\n",
    "        elif z_score < 2.0:\n",
    "            likelihood = np.array([0.7, 0.3])\n",
    "        elif z_score < 3.0:\n",
    "            likelihood = np.array([0.3, 0.7])\n",
    "        else:\n",
    "            likelihood = np.array([0.1, 0.9])\n",
    "        \n",
    "        threat_belief = update(threat_belief, likelihood)\n",
    "        \n",
    "        # Decay toward neutral during normal periods\n",
    "        if z_score < 1.5:\n",
    "            threat_belief[1] = threat_belief[1] * (1 - decay_rate) + 0.5 * decay_rate\n",
    "            threat_belief[0] = 1 - threat_belief[1]\n",
    "        \n",
    "        # Alert if threat probability high\n",
    "        threat_score = threat_belief[1]\n",
    "        alert = z_score > alert_threshold and threat_score > 0.6\n",
    "        \n",
    "        results['threat_scores'].append(threat_score)\n",
    "        results['baselines'].append(baseline)\n",
    "        results['alerts'].append(alert)\n",
    "        results['threat_belief'].append(threat_belief.copy())\n",
    "        \n",
    "        # Update baseline (adaptive)\n",
    "        if z_score < 2.0:  # Only adapt during normal periods\n",
    "            baseline = (1 - adapt_rate) * baseline + adapt_rate * obs\n",
    "            # Update std using exponential moving average\n",
    "            if t >= window_size:\n",
    "                recent_data = data[max(0, t-window_size+1):t+1]\n",
    "                baseline_std = (1 - adapt_rate) * baseline_std + adapt_rate * np.std(recent_data)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test adaptive monitoring\n",
    "# Generate data with drift and anomalies\n",
    "t = np.arange(100)\n",
    "baseline_drift = 100 + 0.1 * t  # Slow drift\n",
    "noise = rng.normal(0, 5, 100)\n",
    "data = baseline_drift + noise\n",
    "\n",
    "# Add anomalies\n",
    "anomaly_indices = [30, 31, 60, 61, 62]\n",
    "for idx in anomaly_indices:\n",
    "    data[idx] += rng.normal(30, 5)\n",
    "\n",
    "result = adaptive_monitor(data)\n",
    "alert_times = np.where(result['alerts'])[0]\n",
    "print(f\"Alerts at times: {alert_times}\")\n",
    "print(f\"Total alerts: {sum(result['alerts'])}\")\n",
    "\n",
    "# Should detect most anomalies\n",
    "assert len(alert_times) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Security Event Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def correlate_events(events, time_window=60, correlation_threshold=0.7):\n",
    "    \"Correlate security events to identify coordinated attacks\"\n",
    "    \n",
    "    # Group events by time window\n",
    "    event_groups = []\n",
    "    current_group = []\n",
    "    \n",
    "    for event in events:\n",
    "        if not current_group or event['timestamp'] - current_group[0]['timestamp'] <= time_window:\n",
    "            current_group.append(event)\n",
    "        else:\n",
    "            if current_group:\n",
    "                event_groups.append(current_group)\n",
    "            current_group = [event]\n",
    "    \n",
    "    if current_group:\n",
    "        event_groups.append(current_group)\n",
    "    \n",
    "    # Analyze each group\n",
    "    correlations = []\n",
    "    \n",
    "    for group in event_groups:\n",
    "        if len(group) < 2:\n",
    "            continue\n",
    "        \n",
    "        # Calculate correlation score based on:\n",
    "        # 1. Temporal proximity\n",
    "        # 2. Source/target similarity\n",
    "        # 3. Attack pattern matching\n",
    "        \n",
    "        time_span = group[-1]['timestamp'] - group[0]['timestamp']\n",
    "        time_score = 1.0 - (time_span / time_window)\n",
    "        \n",
    "        # Check for common sources or targets\n",
    "        sources = [e.get('source', '') for e in group]\n",
    "        targets = [e.get('target', '') for e in group]\n",
    "        \n",
    "        source_overlap = len(set(sources)) / len(sources) if sources else 0\n",
    "        target_overlap = len(set(targets)) / len(targets) if targets else 0\n",
    "        \n",
    "        overlap_score = 1.0 - max(source_overlap, target_overlap)\n",
    "        \n",
    "        # Pattern score (simplified)\n",
    "        event_types = [e['type'] for e in group]\n",
    "        pattern_score = 0.8 if len(set(event_types)) > 2 else 0.3\n",
    "        \n",
    "        # Combined score\n",
    "        correlation_score = (time_score + overlap_score + pattern_score) / 3\n",
    "        \n",
    "        if correlation_score > correlation_threshold:\n",
    "            correlations.append({\n",
    "                'events': group,\n",
    "                'score': correlation_score,\n",
    "                'time_span': time_span,\n",
    "                'event_types': list(set(event_types))\n",
    "            })\n",
    "    \n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test event correlation\n",
    "events = [\n",
    "    {'timestamp': 0, 'type': 'port_scan', 'source': '192.168.1.100', 'target': '10.0.0.1'},\n",
    "    {'timestamp': 5, 'type': 'login_attempt', 'source': '192.168.1.100', 'target': '10.0.0.1'},\n",
    "    {'timestamp': 10, 'type': 'privilege_escalation', 'source': '192.168.1.100', 'target': '10.0.0.1'},\n",
    "    {'timestamp': 100, 'type': 'data_access', 'source': '192.168.1.200', 'target': '10.0.0.2'},\n",
    "    {'timestamp': 105, 'type': 'data_exfiltration', 'source': '192.168.1.200', 'target': '10.0.0.2'}\n",
    "]\n",
    "\n",
    "correlations = correlate_events(events, time_window=30)\n",
    "print(f\"Found {len(correlations)} correlated event groups\")\n",
    "for i, corr in enumerate(correlations):\n",
    "    print(f\"\\nGroup {i+1}: Score={corr['score']:.3f}, Types={corr['event_types']}\")\n",
    "\n",
    "assert len(correlations) >= 1  # Should find at least one correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "__all__ = [\n",
    "    # Threat detection\n",
    "    'intrusion_detection', 'multi_stage_detector',\n",
    "    \n",
    "    # Anomaly detection\n",
    "    'network_anomaly_detector', 'adaptive_monitor',\n",
    "    \n",
    "    # Intelligence and correlation\n",
    "    'fuse_threat_intel', 'correlate_events'\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
